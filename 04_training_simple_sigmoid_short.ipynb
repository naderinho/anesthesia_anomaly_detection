{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsVCXc2r4g3c",
        "outputId": "072c1724-5499-48cb-af6c-131e931b13b5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "### Configuration\n",
        "create_dataset = False\n",
        "\n",
        "def in_google_colab():\n",
        "    \"\"\"Checks if the code is running in Google Colab\n",
        "\n",
        "    Returns:\n",
        "        bool: _description_\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "if in_google_colab():\n",
        "    print(\"Running in Google Colab\")\n",
        "    # Install necessary packages in Google Colab\n",
        "    !rm -r sample_data/\n",
        "    !git clone https://github.com/naderinho/anesthesia_anomaly_detection\n",
        "    !cp -r anesthesia_anomaly_detection/* .\n",
        "    !rm -r anesthesia_anomaly_detection/\n",
        "    !pip install vitaldb\n",
        "    create_dataset = False\n",
        "else:\n",
        "    print(\"Running locally\")\n",
        "\n",
        "### Datasetpath\n",
        "directory = 'data/'\n",
        "datasetpath = 'dataset02/'\n",
        "vitaldbpath = 'vitaldb_tiva/'\n",
        "\n",
        "### Import the necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import vitaldb as vf\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "### Custom functions\n",
        "import modules as md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QPUKpAQ4g3i"
      },
      "outputs": [],
      "source": [
        "###### Create Dataset\n",
        "if create_dataset:\n",
        "    bis = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    bis.name = 'Bispektralindex'\n",
        "    bis.tracks = ['BIS/BIS']\n",
        "    bis.filter = [20, 10, 100]\n",
        "    bis.generateDataset(normalization=md.NormNone)\n",
        "    bis.save('00_bis.npz')\n",
        "\n",
        "    info = md.infoImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    info.generateDataset(normalization=md.NormStandard)\n",
        "    info.save('01_info.npz')\n",
        "\n",
        "    bloodpressure = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    bloodpressure.name = 'bloodpressure'\n",
        "    bloodpressure.tracks = ['Solar8000/ART_DBP', 'Solar8000/ART_MBP', 'Solar8000/ART_SBP']\n",
        "    bloodpressure.filter = [20, 20, 250]\n",
        "    bloodpressure.generateDataset(normalization=md.NormStandard)\n",
        "    bloodpressure.save('02_bloodpressure.npz')\n",
        "\n",
        "    etCO2 = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    etCO2.name = 'End Tidal CO2'\n",
        "    etCO2.tracks = ['Primus/ETCO2']\n",
        "    etCO2.filter = [5, 15, 50]\n",
        "    etCO2.generateDataset(normalization=md.NormStandard)\n",
        "    etCO2.save('02_etCO2.npz')\n",
        "\n",
        "    spO2 = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    spO2.name = 'SpO2'\n",
        "    spO2.tracks = ['Solar8000/PLETH_SPO2']\n",
        "    spO2.filter = [3, 80, 100]\n",
        "    spO2.generateDataset(normalization=md.NormStandard)\n",
        "    spO2.save('02_spO2.npz')\n",
        "\n",
        "    hr = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    hr.name = 'Heart Rate'\n",
        "    hr.tracks = ['Solar8000/HR']\n",
        "    hr.filter = [20, 40, 180]\n",
        "    hr.generateDataset(normalization=md.NormStandard)\n",
        "    hr.save('02_hr.npz')\n",
        "\n",
        "    propofolrate = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    propofolrate.name = 'Propofol Rate'\n",
        "    propofolrate.tracks = ['Orchestra/PPF20_RATE']\n",
        "    propofolrate.filterON = False\n",
        "    propofolrate.generateDataset(normalization=md.NormNone)\n",
        "    propofolrate.save('03_propofol_rate.npz')\n",
        "\n",
        "    remifentanilrate = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    remifentanilrate.name = 'Remifentanil Rate'\n",
        "    remifentanilrate.tracks = ['Orchestra/RFTN20_RATE']\n",
        "    remifentanilrate.filterON = False\n",
        "    remifentanilrate.generateDataset(normalization=md.NormNone)\n",
        "    remifentanilrate.save('03_remifentanil_rate.npz')\n",
        "\n",
        "### Load the datasets\n",
        "bis = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "bis.load('00_bis.npz')\n",
        "\n",
        "info = md.infoImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "info.load('01_info.npz')\n",
        "\n",
        "bloodpressure = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "bloodpressure.load('02_bloodpressure.npz')\n",
        "\n",
        "etCO2 = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "etCO2.load('02_etCO2.npz')\n",
        "\n",
        "spO2 = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "spO2.load('02_spO2.npz')\n",
        "\n",
        "hr = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "hr.load('02_hr.npz')\n",
        "\n",
        "propofolrate = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "propofolrate.load('03_propofol_rate.npz')\n",
        "\n",
        "remifentanilrate = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "remifentanilrate.load('03_remifentanil_rate.npz')\n",
        "\n",
        "train_index, val_index, test_index = bis.split(np.array(bis.index))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auUnKLkV4g3j",
        "outputId": "31e101db-a25d-46ea-a3ff-000922cf0468"
      },
      "outputs": [],
      "source": [
        "########################################## COMBINED MODEL ##########################################\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, ReLU, Dropout, Concatenate, Masking, Conv1D, MaxPooling1D, BatchNormalization, RepeatVector, Lambda\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError, MeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError\n",
        "\n",
        "### LSTM layers for the blood pressure data\n",
        "\n",
        "### Combine the vital data\n",
        "vital_train = np.concatenate([bloodpressure.train_dataset, etCO2.train_dataset, spO2.train_dataset, hr.train_dataset], axis=2)\n",
        "vital_validation = np.concatenate([bloodpressure.validation_dataset, etCO2.validation_dataset, spO2.validation_dataset, hr.validation_dataset], axis=2)\n",
        "vital_test = np.concatenate([bloodpressure.test_dataset, etCO2.test_dataset, spO2.test_dataset, hr.test_dataset], axis=2)\n",
        "\n",
        "### LSTM layers for the vital data\n",
        "input_vital = Input(shape=(None, vital_train.shape[2]))\n",
        "vital_layer = Masking(mask_value=0.0)(input_vital)\n",
        "\n",
        "### INFO layers\n",
        "input_info = Input(shape=(info.train_dataset.shape[1],))\n",
        "info_layer = RepeatVector(vital_train.shape[1])(input_info)\n",
        "\n",
        "## Concatenate the LSTM output with the info layer\n",
        "comb_layer = Concatenate()([vital_layer, info_layer])\n",
        "comb_layer = LSTM(units=32, return_sequences=True)(comb_layer)\n",
        "#comb_layer = BatchNormalization()(comb_layer)\n",
        "comb_layer = LSTM(units=32, return_sequences=True)(comb_layer)\n",
        "#comb_layer = BatchNormalization()(comb_layer)\n",
        "comb_layer = LSTM(units=32, return_sequences=True)(comb_layer)\n",
        "#comb_layer = BatchNormalization()(comb_layer)\n",
        "comb_layer = Dense(units=128, activation='relu')(comb_layer)\n",
        "#comb_layer = BatchNormalization()(comb_layer)\n",
        "comb_layer = Dense(units=32, activation='relu')(comb_layer)\n",
        "comb_layer = BatchNormalization()(comb_layer)\n",
        "\n",
        "\n",
        "output = Dense(units=1, activation='sigmoid')(comb_layer)\n",
        "output = Lambda(lambda x: x * 100)(output)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=[input_vital, input_info], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.MeanSquaredError(),\n",
        "              metrics=['MeanSquaredError','MeanAbsoluteError','RootMeanSquaredError']\n",
        "              )\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rolling mean on BIS data\n",
        "y = pd.DataFrame(bis.train_dataset[:,:,0].T).rolling(min_periods=1,window=20, center=True).mean().to_numpy().T[:,:,np.newaxis]\n",
        "\n",
        "# Define training stop criteria\n",
        "class StopTrainingCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, threshold):\n",
        "        super(StopTrainingCallback, self).__init__()\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs.get('val_loss') is not None:\n",
        "            if logs.get('val_loss') < self.threshold:\n",
        "                print(f\"\\nValidation loss is below {self.threshold}, stopping training.\")\n",
        "                self.model.stop_training = True\n",
        "\n",
        "stop_training_callback = StopTrainingCallback(threshold = 35)\n",
        "\n",
        "\n",
        "\n",
        "# Train the model\n",
        "history = model.fit([vital_train, info.train_dataset],\n",
        "                    y,\n",
        "                    validation_data=([vital_validation, info.validation_dataset], bis.validation_dataset),\n",
        "                    epochs=50,\n",
        "                    batch_size=4,\n",
        "                    callbacks=[stop_training_callback]\n",
        "                    )\n",
        "\n",
        "# Save the model\n",
        "model.save('model.keras')\n",
        "\n",
        "# Save the training history\n",
        "train_score = history.history\n",
        "\n",
        "with open('train_score.pkl', 'wb') as f:\n",
        "    pickle.dump(train_score, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.plotting import training_loss_plot\n",
        "\n",
        "with open('train_score.pkl', 'rb') as f:\n",
        "    train_score = pickle.load(f)\n",
        "\n",
        "plot = training_loss_plot(train_score)\n",
        "plot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Predict on the test set\n",
        "from utils.evaluation import phases_report, phases_report_std\n",
        "\n",
        "y_pred = model.predict([vital_test, info.test_dataset], verbose=0)\n",
        "\n",
        "print('Testmetriken:')\n",
        "\n",
        "report = phases_report(y_pred, bis.test_dataset, propofolrate.test_dataset)\n",
        "report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "phases_report_std(report, y_pred, bis.test_dataset, propofolrate.test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.plotting import full_histogramm_plot\n",
        "\n",
        "plot = full_histogramm_plot(groundtruth = bis.test_dataset, prediction = y_pred)\n",
        "plot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.plotting import single_prediction_plot\n",
        "\n",
        "plot = single_prediction_plot(\n",
        "    case = 3270, \n",
        "    index = test_index, \n",
        "    groundtruth = bis.test_dataset, \n",
        "    prediction = y_pred, \n",
        "    infusion = propofolrate.test_dataset, \n",
        "    error = 'Prediction RMSE',\n",
        "    filename = None)\n",
        "    \n",
        "plot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.plotting import full_prediction_plot\n",
        "\n",
        "full_prediction_plot(index = test_index, groundtruth = bis.test_dataset, prediction = y_pred, infusion = propofolrate.test_dataset)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
