{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsVCXc2r4g3c",
        "outputId": "072c1724-5499-48cb-af6c-131e931b13b5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "### Configuration\n",
        "create_dataset = False\n",
        "\n",
        "def in_google_colab():\n",
        "    \"\"\"Checks if the code is running in Google Colab\n",
        "\n",
        "    Returns:\n",
        "        bool: _description_\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "if in_google_colab():\n",
        "    print(\"Running in Google Colab\")\n",
        "    # Install necessary packages in Google Colab\n",
        "    !rm -r sample_data/\n",
        "    !git clone https://github.com/naderinho/anesthesia_anomaly_detection\n",
        "    !cp -r anesthesia_anomaly_detection/* .\n",
        "    !rm -r anesthesia_anomaly_detection/\n",
        "    !pip install vitaldb\n",
        "    create_dataset = False\n",
        "else:\n",
        "    print(\"Running locally\")\n",
        "\n",
        "### Datasetpath\n",
        "directory = 'data/'\n",
        "datasetpath = 'dataset02/'\n",
        "vitaldbpath = 'vitaldb_tiva/'\n",
        "\n",
        "### Import the necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import vitaldb as vf\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "### Custom functions\n",
        "import modules as md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QPUKpAQ4g3i"
      },
      "outputs": [],
      "source": [
        "###### Create Dataset\n",
        "if create_dataset:\n",
        "    bis = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    bis.name = 'Bispektralindex'\n",
        "    bis.tracks = ['BIS/BIS']\n",
        "    bis.filter = [20, 10, 100]\n",
        "    bis.generateDataset(normalization=md.NormNone)\n",
        "    bis.save('00_bis.npz')\n",
        "\n",
        "    info = md.infoImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    info.generateDataset(normalization=md.NormStandard)\n",
        "    info.save('01_info.npz')\n",
        "\n",
        "    info_non_norm = md.infoImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    info_non_norm.generateDataset(normalization=md.NormNone)\n",
        "    info_non_norm.save('01_info_norm_none.npz')\n",
        "\n",
        "    bloodpressure = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    bloodpressure.name = 'bloodpressure'\n",
        "    bloodpressure.tracks = ['Solar8000/ART_DBP', 'Solar8000/ART_MBP', 'Solar8000/ART_SBP']\n",
        "    bloodpressure.filter = [20, 20, 250]\n",
        "    bloodpressure.generateDataset(normalization=md.NormStandard)\n",
        "    bloodpressure.save('02_bloodpressure.npz')\n",
        "\n",
        "    etCO2 = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    etCO2.name = 'End Tidal CO2'\n",
        "    etCO2.tracks = ['Primus/ETCO2']\n",
        "    etCO2.filter = [5, 15, 50]\n",
        "    etCO2.generateDataset(normalization=md.NormStandard)\n",
        "    etCO2.save('02_etCO2.npz')\n",
        "\n",
        "    spO2 = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    spO2.name = 'SpO2'\n",
        "    spO2.tracks = ['Solar8000/PLETH_SPO2']\n",
        "    spO2.filter = [3, 80, 100]\n",
        "    spO2.generateDataset(normalization=md.NormStandard)\n",
        "    spO2.save('02_spO2.npz')\n",
        "\n",
        "    hr = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    hr.name = 'Heart Rate'\n",
        "    hr.tracks = ['Solar8000/HR']\n",
        "    hr.filter = [20, 40, 180]\n",
        "    hr.generateDataset(normalization=md.NormStandard)\n",
        "    hr.save('02_hr.npz')\n",
        "\n",
        "    propofolrate = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    propofolrate.name = 'Propofol Rate'\n",
        "    propofolrate.tracks = ['Orchestra/PPF20_RATE']\n",
        "    propofolrate.filterON = False\n",
        "    propofolrate.generateDataset(normalization=md.NormNone)\n",
        "    propofolrate.save('03_propofol_rate.npz')\n",
        "\n",
        "    remifentanilrate = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    remifentanilrate.name = 'Remifentanil Rate'\n",
        "    remifentanilrate.tracks = ['Orchestra/RFTN20_RATE']\n",
        "    remifentanilrate.filterON = False\n",
        "    remifentanilrate.generateDataset(normalization=md.NormNone)\n",
        "    remifentanilrate.save('03_remifentanil_rate.npz')\n",
        "\n",
        "### Load the datasets\n",
        "bis = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "bis.load('00_bis.npz')\n",
        "\n",
        "info = md.infoImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "info.load('01_info.npz')\n",
        "\n",
        "info_non_norm = md.infoImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "info_non_norm.load('01_info_norm_none.npz')\n",
        "\n",
        "bloodpressure = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "bloodpressure.load('02_bloodpressure.npz')\n",
        "\n",
        "etCO2 = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "etCO2.load('02_etCO2.npz')\n",
        "\n",
        "spO2 = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "spO2.load('02_spO2.npz')\n",
        "\n",
        "hr = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "hr.load('02_hr.npz')\n",
        "\n",
        "propofolrate = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "propofolrate.load('03_propofol_rate.npz')\n",
        "\n",
        "remifentanilrate = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "remifentanilrate.load('03_remifentanil_rate.npz')\n",
        "\n",
        "train_index, val_index, test_index = bis.split(np.array(bis.index))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Seperate the Data in + 60 years and older patients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "young_index_train = np.where(info_non_norm.train_dataset[:,1] <  60)\n",
        "old_index_train   = np.where(info_non_norm.train_dataset[:,1] >= 60)\n",
        "\n",
        "print(young_index_train[0].shape, old_index_train[0].shape)\n",
        "\n",
        "young_index_val = np.where(info_non_norm.validation_dataset[:,1] <  60)\n",
        "old_index_val   = np.where(info_non_norm.validation_dataset[:,1] >= 60)\n",
        "\n",
        "print(young_index_val[0].shape, old_index_val[0].shape)\n",
        "\n",
        "young_index_test = np.where(info_non_norm.test_dataset[:,1] <  60)\n",
        "old_index_test   = np.where(info_non_norm.test_dataset[:,1] >= 60)\n",
        "\n",
        "print(young_index_test[0].shape, old_index_test[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auUnKLkV4g3j",
        "outputId": "31e101db-a25d-46ea-a3ff-000922cf0468"
      },
      "outputs": [],
      "source": [
        "########################################## COMBINED MODEL ##########################################\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, ReLU, Dropout, Concatenate, Masking, Conv1D, MaxPooling1D, BatchNormalization, RepeatVector, Lambda\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError, MeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError\n",
        "\n",
        "### Blood Pressure Input\n",
        "input_bp = Input(shape=(None, bloodpressure.train_dataset.shape[2]))\n",
        "bp_layer = Masking(mask_value=0.0)(input_bp)\n",
        "\n",
        "bp_layer = LSTM(units=64, return_sequences=True)(bp_layer)\n",
        "bp_layer = BatchNormalization()(bp_layer)\n",
        "bp_layer = LSTM(units=64, return_sequences=True)(bp_layer)\n",
        "bp_layer = BatchNormalization()(bp_layer)\n",
        "bp_layer = LSTM(units=64, return_sequences=True)(bp_layer)\n",
        "bp_layer = BatchNormalization()(bp_layer)\n",
        "bp_layer = LSTM(units=64, return_sequences=True)(bp_layer)\n",
        "bp_layer = BatchNormalization()(bp_layer)\n",
        "bp_layer = LSTM(units=128, return_sequences=True)(bp_layer)\n",
        "bp_layer = BatchNormalization()(bp_layer)\n",
        "bp_layer = LSTM(units=64, return_sequences=True)(bp_layer)\n",
        "bp_layer = BatchNormalization()(bp_layer)\n",
        "bp_layer = LSTM(units=16, return_sequences=True)(bp_layer)\n",
        "bp_layer = BatchNormalization()(bp_layer)\n",
        "bp_layer = LSTM(units=16, return_sequences=True)(bp_layer)\n",
        "bp_layer = BatchNormalization()(bp_layer)\n",
        "bp_layer = Dense(units=16, activation='linear')(bp_layer)\n",
        "\n",
        "### etCO2 Input\n",
        "input_co2 = Input(shape=(None, etCO2.train_dataset.shape[2]))\n",
        "\n",
        "co2_layer = LSTM(units=64, return_sequences=True)(input_co2)\n",
        "co2_layer = BatchNormalization()(co2_layer)\n",
        "co2_layer = LSTM(units=64, return_sequences=True)(co2_layer)\n",
        "co2_layer = BatchNormalization()(co2_layer)\n",
        "co2_layer = LSTM(units=64, return_sequences=True)(co2_layer)\n",
        "co2_layer = BatchNormalization()(co2_layer)\n",
        "co2_layer = LSTM(units=16, return_sequences=True)(co2_layer)\n",
        "co2_layer = BatchNormalization()(co2_layer)\n",
        "co2_layer = LSTM(units=8, return_sequences=True)(co2_layer)\n",
        "co2_layer = BatchNormalization()(co2_layer)\n",
        "co2_layer = Dense(units=8, activation='linear')(co2_layer)\n",
        "\n",
        "### spo2 Input\n",
        "input_spo2 = Input(shape=(None, spO2.train_dataset.shape[2]))\n",
        "\n",
        "spo2_layer = LSTM(units=64, return_sequences=True)(input_spo2)\n",
        "spo2_layer = BatchNormalization()(spo2_layer)\n",
        "spo2_layer = LSTM(units=64, return_sequences=True)(spo2_layer)\n",
        "spo2_layer = BatchNormalization()(spo2_layer)\n",
        "spo2_layer = LSTM(units=64, return_sequences=True)(spo2_layer)\n",
        "spo2_layer = BatchNormalization()(spo2_layer)\n",
        "spo2_layer = LSTM(units=16, return_sequences=True)(spo2_layer)\n",
        "spo2_layer = BatchNormalization()(spo2_layer)\n",
        "spo2_layer = LSTM(units=8, return_sequences=True)(spo2_layer)\n",
        "spo2_layer = BatchNormalization()(spo2_layer)\n",
        "spo2_layer = Dense(units=8, activation='linear')(spo2_layer)\n",
        "\n",
        "# Prpofol layers\n",
        "input_propofol = Input(shape=(None, propofolrate.train_dataset.shape[2]))\n",
        "propofol_layer = BatchNormalization()(input_propofol)\n",
        "propofol_layer = LSTM(units=64, return_sequences=True)(propofol_layer)\n",
        "propofol_layer = BatchNormalization()(propofol_layer)\n",
        "propofol_layer = LSTM(units=64, return_sequences=True)(propofol_layer)\n",
        "propofol_layer = BatchNormalization()(propofol_layer)\n",
        "propofol_layer = LSTM(units=64, return_sequences=True)(propofol_layer)\n",
        "propofol_layer = BatchNormalization()(propofol_layer)\n",
        "propofol_layer = LSTM(units=64, return_sequences=True)(propofol_layer)\n",
        "propofol_layer = BatchNormalization()(propofol_layer)\n",
        "propofol_layer = LSTM(units=128, return_sequences=True)(propofol_layer)\n",
        "propofol_layer = BatchNormalization()(propofol_layer)\n",
        "propofol_layer = LSTM(units=64, return_sequences=True)(propofol_layer)\n",
        "propofol_layer = BatchNormalization()(propofol_layer)\n",
        "propofol_layer = LSTM(units=16, return_sequences=True)(propofol_layer)\n",
        "propofol_layer = BatchNormalization()(propofol_layer)\n",
        "propofol_layer = LSTM(units=16, return_sequences=True)(propofol_layer)\n",
        "propofol_layer = BatchNormalization()(propofol_layer)\n",
        "propofol_layer = Dense(units=16, activation='linear')(propofol_layer)\n",
        "\n",
        "### INFO layers\n",
        "input_info = Input(shape=(info.train_dataset.shape[1],))\n",
        "info_layer = RepeatVector(bloodpressure.train_dataset.shape[1])(input_info)\n",
        "info_layer = Dense(units=16, activation='linear')(info_layer)\n",
        "info_layer = Dense(units=16, activation='sigmoid')(info_layer)\n",
        "\n",
        "\n",
        "## Concatenate the Propofol output with the info layer\n",
        "comb_layer = Concatenate()([bp_layer, co2_layer, spo2_layer, propofol_layer, info_layer])\n",
        "comb_layer = Dense(units=64, activation='linear')(comb_layer)\n",
        "comb_layer = Dense(units=64, activation='relu')(comb_layer)\n",
        "comb_layer = Dense(units=64, activation='relu')(comb_layer)\n",
        "comb_layer = Dense(units=32, activation='relu')(comb_layer)\n",
        "comb_layer = Dense(units=16, activation='relu')(comb_layer)\n",
        "comb_layer = Dense(units=1, activation='relu')(comb_layer)\n",
        "output = Lambda(lambda x: x * 100)(comb_layer)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=[input_bp, input_co2, input_spo2, input_propofol, input_info], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.MeanSquaredError(),\n",
        "              metrics=['MeanSquaredError','MeanAbsoluteError','RootMeanSquaredError']\n",
        "              )\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Training on older patients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define training stop criteria\n",
        "class StopTrainingCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, threshold):\n",
        "        super(StopTrainingCallback, self).__init__()\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs.get('val_loss') is not None:\n",
        "            if logs.get('val_loss') < self.threshold:\n",
        "                print(f\"\\nValidation loss is below {self.threshold}, stopping training.\")\n",
        "                self.model.stop_training = True\n",
        "\n",
        "stop_training_callback = StopTrainingCallback(threshold = 35)\n",
        "\n",
        "\n",
        "if in_google_colab():\n",
        "    # Train the model\n",
        "    history = model.fit([bloodpressure.train_dataset[old_index_train], etCO2.train_dataset[old_index_train], spO2.train_dataset[old_index_train], propofolrate.train_dataset[old_index_train], info.train_dataset[old_index_train]],\n",
        "                        bis.train_dataset[old_index_train],\n",
        "                        validation_data=([bloodpressure.validation_dataset[old_index_val], etCO2.validation_dataset[old_index_val], spO2.validation_dataset[old_index_val], propofolrate.validation_dataset[old_index_val], info.validation_dataset[old_index_val]], bis.validation_dataset[old_index_val]),\n",
        "                        epochs=150,\n",
        "                        callbacks=[stop_training_callback],\n",
        "                        batch_size=4\n",
        "                        )\n",
        "\n",
        "    train_score = history.history\n",
        "\n",
        "    # Save the model\n",
        "    model.save('download/model.keras')\n",
        "\n",
        "    # Save the training history\n",
        "    with open('download/train_score.pkl', 'wb') as f:\n",
        "        pickle.dump(train_score, f)\n",
        "\n",
        "    # Save the prediction\n",
        "    y_pred_young = model.predict([bloodpressure.test_dataset[young_index_test], etCO2.test_dataset[young_index_test], spO2.test_dataset[young_index_test], propofolrate.test_dataset[young_index_test], info.test_dataset[young_index_test]], verbose=0)\n",
        "    with open('download/prediction_young.pkl', 'wb') as f:\n",
        "        pickle.dump(y_pred_young, f)\n",
        "\n",
        "    y_pred_old = model.predict([bloodpressure.test_dataset[old_index_test], etCO2.test_dataset[old_index_test], spO2.test_dataset[old_index_test], propofolrate.test_dataset[old_index_test], info.test_dataset[old_index_test]], verbose=0)\n",
        "    with open('download/prediction_old.pkl', 'wb') as f:\n",
        "        pickle.dump(y_pred_old, f)\n",
        "\n",
        "else: \n",
        "    # Load train score data\n",
        "    with open('train_score_old.pkl', 'rb') as f:\n",
        "        train_score = pickle.load(f)\n",
        "    \n",
        "    # Load test prediction data\n",
        "    with open('prediction_young.pkl', 'rb') as f:\n",
        "        y_pred_young = pickle.load(f)\n",
        "\n",
        "    with open('prediction_old.pkl', 'rb') as f:\n",
        "        y_pred_olde = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.plotting import training_loss_plot\n",
        "\n",
        "plot = training_loss_plot(train_score, filename='download/training_loss_old.pdf')\n",
        "plot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing old"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Predict on the test set\n",
        "from utils.evaluation import phases_report, phases_report_std\n",
        "\n",
        "print('Testmetriken:')\n",
        "\n",
        "report = phases_report(y_pred_old, bis.test_dataset[old_index_test], propofolrate.test_dataset[old_index_test])\n",
        "report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "phases_report_std(report, y_pred_old, bis.test_dataset[old_index_test], propofolrate.test_dataset[old_index_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.plotting import full_histogramm_plot\n",
        "\n",
        "plot = full_histogramm_plot(groundtruth = bis.test_dataset[old_index_test], prediction = y_pred_old, filename='download/histogramm_old.pdf')\n",
        "plot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.plotting import single_prediction_plot\n",
        "\n",
        "for case in test_index[old_index_test]:\n",
        "    single_prediction_plot(\n",
        "        case = case, \n",
        "        index = test_index[old_index_test], \n",
        "        groundtruth = bis.test_dataset[old_index_test], \n",
        "        prediction = y_pred_old, \n",
        "        infusion = propofolrate.test_dataset[old_index_test], \n",
        "        error = 'Prediction RMSE',\n",
        "        filename = 'download/' + str(case) + '_male.pdf')\n",
        "\n",
        "print('Finished')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing young"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Predict on the test set\n",
        "from utils.evaluation import phases_report, phases_report_std\n",
        "\n",
        "print('Testmetriken:')\n",
        "\n",
        "report = phases_report(y_pred_young, bis.test_dataset[young_index_test], propofolrate.test_dataset[young_index_test])\n",
        "report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "phases_report_std(report, y_pred_young, bis.test_dataset[young_index_test], propofolrate.test_dataset[young_index_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.plotting import full_histogramm_plot\n",
        "\n",
        "plot = full_histogramm_plot(groundtruth = bis.test_dataset[young_index_test], prediction = y_pred_young, filename='download/histogramm_young.pdf')\n",
        "plot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.plotting import single_prediction_plot\n",
        "\n",
        "for case in test_index[young_index_test]:\n",
        "    single_prediction_plot(\n",
        "        case = case, \n",
        "        index = test_index[young_index_test], \n",
        "        groundtruth = bis.test_dataset[young_index_test], \n",
        "        prediction = y_pred_young, \n",
        "        infusion = propofolrate.test_dataset[young_index_test], \n",
        "        error = 'Prediction RMSE',\n",
        "        filename = 'download/' + str(case) + '_young.pdf')\n",
        "\n",
        "print('Finished')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
