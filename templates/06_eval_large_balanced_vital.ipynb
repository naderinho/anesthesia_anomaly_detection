{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsVCXc2r4g3c",
        "outputId": "072c1724-5499-48cb-af6c-131e931b13b5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "### Configuration\n",
        "create_dataset = False\n",
        "\n",
        "def in_google_colab():\n",
        "    \"\"\"Checks if the code is running in Google Colab\n",
        "\n",
        "    Returns:\n",
        "        bool: _description_\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "if in_google_colab():\n",
        "    print(\"Running in Google Colab\")\n",
        "    # Install necessary packages in Google Colab\n",
        "    !rm -r sample_data/\n",
        "    !git clone https://github.com/naderinho/anesthesia_anomaly_detection\n",
        "    !cp -r anesthesia_anomaly_detection/* .\n",
        "    !rm -r anesthesia_anomaly_detection/\n",
        "    !pip install vitaldb\n",
        "    create_dataset = False\n",
        "else:\n",
        "    print(\"Running locally\")\n",
        "\n",
        "### Datasetpath\n",
        "directory = 'data/'\n",
        "datasetpath = 'dataset03/'\n",
        "vitaldbpath = 'vitaldb_sevofl/'\n",
        "\n",
        "### Import the necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import vitaldb as vf\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "### Custom functions\n",
        "import modules as md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QPUKpAQ4g3i"
      },
      "outputs": [],
      "source": [
        "###### Create Dataset\n",
        "if create_dataset:\n",
        "    bis = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    bis.name = 'Bispektralindex'\n",
        "    bis.tracks = ['BIS/BIS']\n",
        "    bis.filter = [20, 10, 100]\n",
        "    bis.generateDataset(normalization=md.NormNone)\n",
        "    bis.save('00_bis.npz')\n",
        "\n",
        "    info = md.infoImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    info.generateDataset(normalization=md.NormStandard)\n",
        "    info.save('01_info.npz')\n",
        "\n",
        "    bloodpressure = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    bloodpressure.name = 'bloodpressure'\n",
        "    bloodpressure.tracks = ['Solar8000/ART_DBP', 'Solar8000/ART_MBP', 'Solar8000/ART_SBP']\n",
        "    bloodpressure.filter = [20, 20, 250]\n",
        "    bloodpressure.generateDataset(normalization=md.NormStandard)\n",
        "    bloodpressure.save('02_bloodpressure.npz')\n",
        "\n",
        "    etCO2 = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    etCO2.name = 'End Tidal CO2'\n",
        "    etCO2.tracks = ['Primus/ETCO2']\n",
        "    etCO2.filter = [5, 15, 50]\n",
        "    etCO2.generateDataset(normalization=md.NormStandard)\n",
        "    etCO2.save('02_etCO2.npz')\n",
        "\n",
        "    spO2 = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    spO2.name = 'SpO2'\n",
        "    spO2.tracks = ['Solar8000/PLETH_SPO2']\n",
        "    spO2.filter = [3, 80, 100]\n",
        "    spO2.generateDataset(normalization=md.NormStandard)\n",
        "    spO2.save('02_spO2.npz')\n",
        "\n",
        "    hr = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    hr.name = 'Heart Rate'\n",
        "    hr.tracks = ['Solar8000/HR']\n",
        "    hr.filter = [20, 40, 180]\n",
        "    hr.generateDataset(normalization=md.NormStandard)\n",
        "    hr.save('02_hr.npz')\n",
        "\n",
        "### Load the datasets\n",
        "bis = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "bis.load('00_bis.npz')\n",
        "\n",
        "info = md.infoImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "info.load('01_info.npz')\n",
        "\n",
        "bloodpressure = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "bloodpressure.load('02_bloodpressure.npz')\n",
        "\n",
        "etCO2 = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "etCO2.load('02_etCO2.npz')\n",
        "\n",
        "spO2 = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "spO2.load('02_spO2.npz')\n",
        "\n",
        "hr = md.VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "hr.load('02_hr.npz')\n",
        "\n",
        "\n",
        "train_index, val_index, test_index = bis.split(np.array(bis.index))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auUnKLkV4g3j",
        "outputId": "31e101db-a25d-46ea-a3ff-000922cf0468"
      },
      "outputs": [],
      "source": [
        "########################################## COMBINED MODEL ##########################################\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, ReLU, Dropout, Concatenate, Masking, Conv1D, MaxPooling1D, BatchNormalization, RepeatVector, Lambda\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError, MeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError\n",
        "\n",
        "### Blood Pressure Input\n",
        "input_bp = Input(shape=(None, bloodpressure.train_dataset.shape[2]))\n",
        "bp_layer = Masking(mask_value=0.0)(input_bp)\n",
        "\n",
        "bp_layer = LSTM(units=64, return_sequences=True)(bp_layer)\n",
        "bp_layer = BatchNormalization()(bp_layer)\n",
        "bp_layer = LSTM(units=64, return_sequences=True)(bp_layer)\n",
        "bp_layer = BatchNormalization()(bp_layer)\n",
        "bp_layer = LSTM(units=64, return_sequences=True)(bp_layer)\n",
        "bp_layer = BatchNormalization()(bp_layer)\n",
        "bp_layer = LSTM(units=64, return_sequences=True)(bp_layer)\n",
        "bp_layer = BatchNormalization()(bp_layer)\n",
        "bp_layer = LSTM(units=128, return_sequences=True)(bp_layer)\n",
        "bp_layer = BatchNormalization()(bp_layer)\n",
        "bp_layer = LSTM(units=64, return_sequences=True)(bp_layer)\n",
        "bp_layer = BatchNormalization()(bp_layer)\n",
        "bp_layer = LSTM(units=16, return_sequences=True)(bp_layer)\n",
        "bp_layer = BatchNormalization()(bp_layer)\n",
        "bp_layer = LSTM(units=16, return_sequences=True)(bp_layer)\n",
        "bp_layer = BatchNormalization()(bp_layer)\n",
        "bp_layer = Dense(units=16, activation='linear')(bp_layer)\n",
        "\n",
        "### etCO2 Input\n",
        "input_co2 = Input(shape=(None, etCO2.train_dataset.shape[2]))\n",
        "\n",
        "co2_layer = LSTM(units=64, return_sequences=True)(input_co2)\n",
        "co2_layer = BatchNormalization()(co2_layer)\n",
        "co2_layer = LSTM(units=64, return_sequences=True)(co2_layer)\n",
        "co2_layer = BatchNormalization()(co2_layer)\n",
        "co2_layer = LSTM(units=64, return_sequences=True)(co2_layer)\n",
        "co2_layer = BatchNormalization()(co2_layer)\n",
        "co2_layer = LSTM(units=16, return_sequences=True)(co2_layer)\n",
        "co2_layer = BatchNormalization()(co2_layer)\n",
        "co2_layer = LSTM(units=8, return_sequences=True)(co2_layer)\n",
        "co2_layer = BatchNormalization()(co2_layer)\n",
        "co2_layer = Dense(units=8, activation='linear')(co2_layer)\n",
        "\n",
        "### spo2 Input\n",
        "input_spo2 = Input(shape=(None, spO2.train_dataset.shape[2]))\n",
        "\n",
        "spo2_layer = LSTM(units=64, return_sequences=True)(input_spo2)\n",
        "spo2_layer = BatchNormalization()(spo2_layer)\n",
        "spo2_layer = LSTM(units=64, return_sequences=True)(spo2_layer)\n",
        "spo2_layer = BatchNormalization()(spo2_layer)\n",
        "spo2_layer = LSTM(units=64, return_sequences=True)(spo2_layer)\n",
        "spo2_layer = BatchNormalization()(spo2_layer)\n",
        "spo2_layer = LSTM(units=16, return_sequences=True)(spo2_layer)\n",
        "spo2_layer = BatchNormalization()(spo2_layer)\n",
        "spo2_layer = LSTM(units=8, return_sequences=True)(spo2_layer)\n",
        "spo2_layer = BatchNormalization()(spo2_layer)\n",
        "spo2_layer = Dense(units=8, activation='linear')(spo2_layer)\n",
        "\n",
        "### INFO layers\n",
        "input_info = Input(shape=(info.train_dataset.shape[1],))\n",
        "info_layer = RepeatVector(bloodpressure.train_dataset.shape[1])(input_info)\n",
        "info_layer = Dense(units=16, activation='linear')(info_layer)\n",
        "info_layer = Dense(units=16, activation='sigmoid')(info_layer)\n",
        "\n",
        "\n",
        "## Concatenate the Sevoflurane output with the info layer\n",
        "comb_layer = Concatenate()([bp_layer, co2_layer, spo2_layer, info_layer])\n",
        "comb_layer = Dense(units=64, activation='linear')(comb_layer)\n",
        "comb_layer = Dense(units=64, activation='relu')(comb_layer)\n",
        "comb_layer = Dense(units=64, activation='relu')(comb_layer)\n",
        "comb_layer = Dense(units=32, activation='relu')(comb_layer)\n",
        "comb_layer = Dense(units=16, activation='relu')(comb_layer)\n",
        "comb_layer = Dense(units=1, activation=ReLU(max_value=1.0))(comb_layer)\n",
        "output = Lambda(lambda x: x * 100)(comb_layer)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=[input_bp, input_co2, input_spo2, input_info], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.MeanSquaredError(),\n",
        "              metrics=['MeanSquaredError','MeanAbsoluteError','RootMeanSquaredError']\n",
        "              )\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rolling mean on BIS data\n",
        "y = pd.DataFrame(bis.train_dataset[:,:,0].T).rolling(min_periods=1,window=3, center=True).mean().to_numpy().T[:,:,np.newaxis]\n",
        "\n",
        "# Define training stop criteria\n",
        "class StopTrainingCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, threshold):\n",
        "        super(StopTrainingCallback, self).__init__()\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs.get('val_loss') is not None:\n",
        "            if logs.get('val_loss') < self.threshold:\n",
        "                print(f\"\\nValidation loss is below {self.threshold}, stopping training.\")\n",
        "                self.model.stop_training = True\n",
        "\n",
        "stop_training_callback = StopTrainingCallback(threshold = 35)\n",
        "\n",
        "\n",
        "if in_google_colab():\n",
        "    # Train the model\n",
        "    history = model.fit([bloodpressure.train_dataset, etCO2.train_dataset, spO2.train_dataset, info.train_dataset],\n",
        "                        y,\n",
        "                        validation_data=([bloodpressure.validation_dataset, etCO2.validation_dataset, spO2.validation_dataset, info.validation_dataset], bis.validation_dataset),\n",
        "                        epochs=150,\n",
        "                        callbacks=[stop_training_callback],\n",
        "                        batch_size=4\n",
        "                        )\n",
        "\n",
        "    train_score = history.history\n",
        "\n",
        "    # Save the model\n",
        "    model.save('download/model.keras')\n",
        "\n",
        "    # Save the training history\n",
        "    with open('download/train_score.pkl', 'wb') as f:\n",
        "        pickle.dump(train_score, f)\n",
        "\n",
        "    # Save the prediction\n",
        "    y_pred = model.predict([bloodpressure.test_dataset, etCO2.test_dataset, spO2.test_dataset, info.test_dataset], verbose=0)\n",
        "    with open('download/prediction.pkl', 'wb') as f:\n",
        "        pickle.dump(y_pred, f)\n",
        "\n",
        "else: \n",
        "    # Load train score data\n",
        "    with open('history_epoch_100.pkl', 'rb') as f:\n",
        "        train_score = pickle.load(f)\n",
        "    \n",
        "    # Load test prediction data\n",
        "    with open('prediction.pkl', 'rb') as f:\n",
        "        y_pred = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def training_loss_plot(train_score, filename: str = None):\n",
        "\n",
        "    epoch = range(1,len(train_score['loss'])+1)\n",
        "\n",
        "    # Plot configuration\n",
        "    plt.figure(figsize=(15/2.54, 8/2.54))\n",
        "    plt.rcParams['font.size'] = 10\n",
        "\n",
        "    color1 = (0, 0, 0)\n",
        "    color2 = (1, 1, 1)\n",
        "    color3 = (159/255, 182/255, 196/255)\n",
        "    color4 = (125/255, 102/255, 102/255)\n",
        "    color5 = (153/255, 0, 0)\n",
        "\n",
        "    # Actual plot\n",
        "    plt.plot(epoch, train_score['loss'], label='Training Loss', color=color1, marker='^', markerfacecolor=color1)\n",
        "    plt.plot(epoch, train_score['val_loss'], label='Validation Loss', color=color1, marker='s', markerfacecolor=color2)\n",
        "\n",
        "    # Title and labels\n",
        "    #plt.title('Training Model loss')\n",
        "    plt.xlabel('Training Epoch')\n",
        "    plt.ylabel('Training Loss')\n",
        "    plt.yscale(\"log\")\n",
        "    plt.xlim(0, len(train_score['loss'])+1)\n",
        "    plt.legend(loc='lower center', bbox_to_anchor=(1.25, 0.78))\n",
        "\n",
        "    # Axis settings\n",
        "    ax = plt.gca()\n",
        "    ax.spines['left'].set_linewidth(1.5)\n",
        "    ax.spines['bottom'].set_linewidth(1.5)\n",
        "\n",
        "    x = epoch[-1] * 1.1\n",
        "\n",
        "    y1 = 30 \n",
        "    ax.set_ylim(bottom=y1)\n",
        "\n",
        "    plt.text(x, y1, s='Batch-Größe: 4', fontsize=10)\n",
        "    y2 = y1 + 10\n",
        "    y0 = y1\n",
        "\n",
        "    plt.text(x, y2, s='Training: '+ '{:d}'.format(len(train_score['loss']))+ ' Epochen', fontsize=10)\n",
        "    y0 = y1\n",
        "    y1 = y2\n",
        "    y2 = y1**2 / y0\n",
        "\n",
        "\n",
        "    plt.text(x, y2, s='Loss: Mean Squared Error', fontsize=10)\n",
        "    y0 = y1\n",
        "    y1 = y2\n",
        "    y2 = y1**2 / y0\n",
        "\n",
        "    plt.text(x, y2, s='Optimierer: Adam', fontsize=10)\n",
        "    y0 = y1\n",
        "    y1 = y2\n",
        "    y2 = y1**2 / y0\n",
        "\n",
        "    plt.text(x, y2, s='Modellparameter:', fontsize=10, fontweight='bold')\n",
        "\n",
        "    plt.grid(True, linewidth=1.0)\n",
        "    if filename != None:\n",
        "        plt.savefig(filename, bbox_inches='tight', pad_inches=0.2, format='pdf')\n",
        "\n",
        "    return plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot = training_loss_plot(train_score, filename='download/training_loss.pdf')\n",
        "plot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_anaesthesia_phases_balanced(bis_dataset: np.array ,mac_dataset: np.array, N: int = 60) -> dict:\n",
        "    anesthesia_phases = []\n",
        "    \n",
        "    for bis, mac in zip(bis_dataset, mac_dataset):\n",
        "        conv_bis = np.convolve(bis[:,0], np.ones(N)/N, mode='valid')\n",
        "        conv_mac = np.convolve(mac[:,0], np.ones(N)/N, mode='valid')\n",
        "        index1 = np.argmax(conv_bis < 60) + 2 * N\n",
        "        index2 = np.where(conv_mac > 0.5)[0][-1] - N\n",
        "        anesthesia_phases.append([index1, index2])\n",
        "\n",
        "    return anesthesia_phases\n",
        "\n",
        "def phases_report(prediction: np.array, groundtruth: np.array, mac: np.array) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    From a given BIS prediction with the corresponding groundtruth values, this function\n",
        "    calculates the MSE, MAE and RMSE for the whole dataset and the three anesthesia phases\n",
        "    (Induction, Maintenance, Recovery). The function also calculates the same metrics for a\n",
        "    baseline model that always predicts a BIS value of 41.0.\n",
        "\n",
        "    Args:\n",
        "        prediction (np.array): predicted BIS values\n",
        "        groundtruth (np.array): measured BIS values\n",
        "        propofolrate (np.array): infusion rate of propofol 20mg/ml in ml/h\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: with the calculated metrics for the whole dataset and the three anesthesia phases\n",
        "    \"\"\"\n",
        "\n",
        "    baseline = np.ones(groundtruth.shape) * 41.0\n",
        "\n",
        "    phases = get_anaesthesia_phases_balanced(bis_dataset=groundtruth, mac_dataset=mac)\n",
        "\n",
        "    # Create the three datasets\n",
        "    all_pred, induction_pred, maintenance_pred, recovery_pred = np.copy(prediction), np.copy(prediction), np.copy(prediction), np.copy(prediction)\n",
        "    all_base, induction_base, maintenance_base, recovery_base = np.copy(baseline), np.copy(baseline), np.copy(baseline), np.copy(baseline)\n",
        "\n",
        "    all_pred[groundtruth == 0.0] = np.nan\n",
        "    all_base[groundtruth == 0.0] = np.nan\n",
        "\n",
        "    for i, phase in enumerate(phases):\n",
        "        induction_pred[i,phase[0]:-1,:] = np.nan\n",
        "        maintenance_pred[i,0:phase[0],:] = np.nan\n",
        "        maintenance_pred[i,phase[1]:-1,:] = np.nan\n",
        "        recovery_pred[i,0:phase[1],:] = np.nan\n",
        "        recovery_pred[i,np.where(groundtruth[i] == 0)[0][0]:-1,:] = np.nan\n",
        "\n",
        "        induction_base[i,phase[0]:-1,:] = np.nan\n",
        "        maintenance_base[i,0:phase[0],:] = np.nan\n",
        "        maintenance_base[i,phase[1]:-1,:] = np.nan\n",
        "        recovery_base[i,0:phase[1],:] = np.nan\n",
        "        recovery_base[i,np.where(groundtruth[i] == 0)[0][0]:-1,:] = np.nan\n",
        "\n",
        "    table_index = ['All', 'Induction', 'Maintenance', 'Recovery']\n",
        "\n",
        "    results = pd.DataFrame(index=table_index, columns=['Prediction MSE', 'Baseline MSE', 'Prediction MAE', 'Baseline MAE', 'Prediction RMSE', 'Baseline RMSE'])\n",
        "\n",
        "    for i, section in enumerate([[all_pred, all_base], [induction_pred, induction_base], [maintenance_pred, maintenance_base], [recovery_pred, recovery_base]]):\n",
        "        results.loc[table_index[i]] = [\n",
        "            np.nanmean(np.square(groundtruth - section[0])),           # MSE Prediction\n",
        "            np.nanmean(np.square(groundtruth - section[1])),           # MSE Baseline\n",
        "            np.nanmean(np.abs(groundtruth - section[0])),              # MAE Prediction\n",
        "            np.nanmean(np.abs(groundtruth - section[1])),              # MAE Baseline\n",
        "            np.sqrt(np.nanmean(np.square(section[0] - groundtruth))),   # RMSE Prediction\n",
        "            np.sqrt(np.nanmean(np.square(section[1] - groundtruth)))    # RMSE Baseline\n",
        "        ]\n",
        "\n",
        "    return results\n",
        "\n",
        "def phases_report_std(report: pd.DataFrame, prediction: np.array, groundtruth: np.array, propofolrate: np.array) -> pd.DataFrame:\n",
        "    sets = prediction.shape[0]\n",
        "\n",
        "    evaluation = np.zeros((sets,4,6))\n",
        "\n",
        "    for i in range(0,sets):\n",
        "        evaluation[i] = phases_report(prediction[i:i+1], groundtruth[i:i+1], propofolrate[i:i+1])\n",
        "\n",
        "    # Prediction RMSE min/max (5)\n",
        "\n",
        "    table_index = ['All     ', 'Induction', 'Maintenance', 'Recovery']\n",
        "\n",
        "    for j, phase in enumerate(table_index):\n",
        "        print(phase, '\\tmin: \\t', np.argmin(evaluation[:,j,5]), '\\tmax: \\t', np.argmax(evaluation[:,j,5])),'(', '{:.3f}'.format(np.max(evaluation[:,j,5]))\n",
        "\n",
        "    data = np.std(evaluation, axis=0)\n",
        "    return pd.DataFrame(data, index=report.index, columns=report.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Predict on the test set\n",
        "\n",
        "print('Testmetriken:')\n",
        "\n",
        "report = phases_report(y_pred, bis.test_dataset, mac.test_dataset)\n",
        "report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "phases_report_std(report, y_pred, bis.test_dataset, mac.test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.plotting import full_histogramm_plot\n",
        "\n",
        "plot = full_histogramm_plot(groundtruth = bis.test_dataset, prediction = y_pred, filename='download/histogramm.pdf')\n",
        "plot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def single_prediction_plot(case: int, index: np.array, groundtruth: np.array, prediction: np.array, mac: np.array = None, error: bool = None, filename: str = None):\n",
        "\n",
        "    j = np.where(index == case)[0][0]\n",
        "\n",
        "    end = np.where(groundtruth[j] == 0)[0][0]\n",
        "\n",
        "    time = np.arange(0, prediction[j,:end].shape[0]) * 10 / 60\n",
        "\n",
        "    plt.figure(figsize=(12/2.54, 6/2.54))\n",
        "    plt.rcParams['font.size'] = 10\n",
        "\n",
        "    # Colors\n",
        "    color1 = (0, 0, 0)\n",
        "    color2 = (1, 1, 1)\n",
        "    color3 = (159/255, 182/255, 196/255)\n",
        "    color4 = (125/255, 102/255, 102/255)\n",
        "    color5 = (153/255, 0, 0)\n",
        "\n",
        "    plt.plot(time,groundtruth[j,:end], label='Ground Truth', color=color1)\n",
        "    plt.plot(time,prediction[j,:end], label='Prediction', color=color5)\n",
        "    \n",
        "    plt.xlabel('Operationszeit $t_{OP}$')\n",
        "    plt.ylabel('Bispektralindex $BIS$')\n",
        "\n",
        "    # Axis settings\n",
        "    ax = plt.gca()\n",
        "    ax.spines['left'].set_linewidth(1.5)\n",
        "    ax.spines['bottom'].set_linewidth(1.5)\n",
        "\n",
        "    # Limits\n",
        "    ax.set_ylim(bottom=0, top=100)\n",
        "    ax.set_xlim(left=0, right=time[-1])\n",
        "\n",
        "    # Einheiten auf x-Achse\n",
        "    xunit = 'min'\n",
        "    ticks = ax.get_xticks()\n",
        "    ticks = [int(tick) for tick in ticks]\n",
        "    ticks_with_units = [xunit if i == len(ticks) - 2 else ticks[i] for i in range(len(ticks))]\n",
        "    ax.set_xticks(ticks)\n",
        "    ax.set_xticklabels(ticks_with_units)\n",
        "\n",
        "    # Einheiten auf y-Achse\n",
        "    yunit = '--'\n",
        "    ticks = ax.get_yticks()\n",
        "    ticks = [int(tick) for tick in ticks]\n",
        "    ticks_with_units = [yunit if i == len(ticks) - 2 else ticks[i] for i in range(len(ticks))]\n",
        "    ax.set_yticks(ticks)\n",
        "    ax.set_yticklabels(ticks_with_units)\n",
        "\n",
        "    plt.grid(True, linewidth=1.0)\n",
        "\n",
        "    x = ax.get_xticks()[-1] * 1.05\n",
        "    x2 = ax.get_xticks()[-1] * 1.3\n",
        "\n",
        "    ### Show prediction error\n",
        "    if error is not None:\n",
        "        error_calc = phases_report(prediction[j:j+1], groundtruth[j:j+1], mac[j:j+1])[error]\n",
        "        plt.text(x, 50, s= error + ':', fontweight='bold')\n",
        "        plt.text(x, 36, s='Gesamt:')\n",
        "        plt.text(x, 24, s='Einleitung:')\n",
        "        plt.text(x, 12, s='Narkose:')\n",
        "        plt.text(x, 0,  s='Ausleitung:')\n",
        "        plt.text(x, -22,  s='Case-ID:')\n",
        "\n",
        "        plt.text(x2, 36, s='{:.2f}'.format(error_calc['All']))\n",
        "        plt.text(x2, 24, s='{:.2f}'.format(error_calc['Induction']))\n",
        "        plt.text(x2, 12, s='{:.2f}'.format(error_calc['Maintenance']))\n",
        "        plt.text(x2, 0,  s='{:.2f}'.format(error_calc['Recovery']))\n",
        "        plt.text(x2, -22,s=str(case))\n",
        "    else: \n",
        "        sex = cases.loc[case]['sex'].replace(\"M\", \"Männlich\").replace(\"F\", \"Weiblich\")\n",
        "        \n",
        "        plt.text(x, 50, s='Fallinformationen:', fontweight='bold')\n",
        "        plt.text(x, 36, s='Case ID: ' + str(case))\n",
        "        plt.text(x, 24, s='Alter: ' + str(int(cases.loc[case]['age'])) + ' Jahre')\n",
        "        plt.text(x, 12, s='Geschlecht: ' + sex)\n",
        "        plt.text(x, 0,  s='BMI: ' + str(cases.loc[case]['bmi']))\n",
        "\n",
        "    ### Legend\n",
        "    dy = 0\n",
        "    if mac is None:\n",
        "        dy = 0.1\n",
        "    plt.legend(loc='lower center', bbox_to_anchor=(1.25, 0.6+dy))\n",
        "\n",
        "    if filename != None:\n",
        "        plt.savefig(filename, bbox_inches='tight', pad_inches=0.2, format='pdf')\n",
        "\n",
        "    return plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for case in test_index:\n",
        "    single_prediction_plot(\n",
        "        case = case, \n",
        "        index = test_index, \n",
        "        groundtruth = bis.test_dataset, \n",
        "        prediction = y_pred, \n",
        "        mac = mac.test_dataset, \n",
        "        error = 'Prediction RMSE',\n",
        "        filename = 'download/' + str(case) + '.pdf')\n",
        "\n",
        "print('Finished')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.plotting import full_prediction_plot\n",
        "\n",
        "full_prediction_plot(index = test_index, groundtruth = bis.test_dataset, prediction = y_pred, infusion = mac.test_dataset)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
