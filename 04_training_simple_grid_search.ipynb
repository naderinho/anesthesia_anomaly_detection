{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsVCXc2r4g3c",
        "outputId": "2080f8cd-0367-448a-f397-8666b3031658"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Google Colab\n",
            "Cloning into 'anesthesia_anomaly_detection'...\n",
            "remote: Enumerating objects: 133, done.\u001b[K\n",
            "remote: Counting objects: 100% (133/133), done.\u001b[K\n",
            "remote: Compressing objects: 100% (108/108), done.\u001b[K\n",
            "remote: Total 133 (delta 39), reused 107 (delta 21), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (133/133), 28.71 MiB | 6.77 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n",
            "Collecting vitaldb\n",
            "  Downloading vitaldb-1.4.9-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m191.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting astetik\n",
            "  Downloading astetik-1.16-py2.py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chances\n",
            "  Downloading chances-0.1.9-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kerasplotlib\n",
            "  Downloading kerasplotlib-1.0-py3-none-any.whl (4.3 kB)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (0.14.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Collecting wrangle\n",
            "  Downloading wrangle-0.7.6-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vitaldb) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from vitaldb) (2.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vitaldb) (2.31.0)\n",
            "Collecting wfdb (from vitaldb)\n",
            "  Downloading wfdb-4.1.2-py3-none-any.whl (159 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.0/160.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting geonamescache (from astetik)\n",
            "  Downloading geonamescache-2.0.0-py3-none-any.whl (26.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from astetik) (7.34.0)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.10/dist-packages (from astetik) (0.5.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from astetik) (1.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from astetik) (0.13.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from chances) (1.11.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from kerasplotlib) (3.7.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (24.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from wrangle) (2.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->vitaldb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->vitaldb) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->vitaldb) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy->astetik) (1.16.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->astetik) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->astetik)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->astetik) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->astetik) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->astetik) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->astetik) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->astetik) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->astetik) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->astetik) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->astetik) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->kerasplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->kerasplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->kerasplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->kerasplotlib) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->kerasplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->kerasplotlib) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vitaldb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vitaldb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vitaldb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vitaldb) (2024.6.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->astetik) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->astetik) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->wrangle) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->wrangle) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow->wrangle) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->wrangle) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->wrangle) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->wrangle) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->wrangle) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->wrangle) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->wrangle) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->wrangle) (3.20.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->wrangle) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->wrangle) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->wrangle) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->wrangle) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->wrangle) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->wrangle) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->wrangle) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->wrangle) (2.15.0)\n",
            "Requirement already satisfied: SoundFile>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from wfdb->vitaldb) (0.12.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->wrangle) (0.43.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->astetik) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->astetik) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->astetik) (0.2.13)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from SoundFile>=0.10.0->wfdb->vitaldb) (1.16.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->wrangle) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->wrangle) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->wrangle) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->wrangle) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->wrangle) (3.0.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->SoundFile>=0.10.0->wfdb->vitaldb) (2.22)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->wrangle) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->wrangle) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->wrangle) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->wrangle) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow->wrangle) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->wrangle) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->wrangle) (3.2.2)\n",
            "Installing collected packages: geonamescache, jedi, chances, wfdb, kerasplotlib, vitaldb, wrangle, astetik\n",
            "Successfully installed astetik-1.16 chances-0.1.9 geonamescache-2.0.0 jedi-0.19.1 kerasplotlib-1.0 vitaldb-1.4.9 wfdb-4.1.2 wrangle-0.7.6\n",
            "Collecting talos\n",
            "  Downloading talos-1.4-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m698.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: talos\n",
            "Successfully installed talos-1.4\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "### Configuration\n",
        "create_dataset = False\n",
        "\n",
        "def in_google_colab():\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "# Get the platform\n",
        "if in_google_colab():\n",
        "    print(\"Running in Google Colab\")\n",
        "    !git clone https://github.com/naderinho/anesthesia_anomaly_detection\n",
        "    !pip install vitaldb astetik chances kerasplotlib statsmodels tqdm wrangle\n",
        "    !pip install --no-deps talos\n",
        "    directory = 'anesthesia_anomaly_detection/data/'\n",
        "    create_dataset = False\n",
        "else:\n",
        "    print(\"Running locally\")\n",
        "    directory = 'data/'\n",
        "\n",
        "### Datasetpath\n",
        "datasetpath = 'dataset01/'\n",
        "vitaldbpath = 'vitaldb_tiva/'\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import vitaldb as vf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "apfldbrf4g3g"
      },
      "outputs": [],
      "source": [
        "from scipy import ndimage\n",
        "\n",
        "def outlierfilter(data: pd.DataFrame,threshhold: float, iterations: int, min: float, max: float):\n",
        "    \"\"\"\n",
        "    A filter function, which calculates the gradient of a given Pandas DataFram Timeseries\n",
        "    and performs a binary dilation on datapoints which exceed a certain treshhold, to detect\n",
        "    and remove unwanted outliers in the dataset. Additionally all values exceeding a given\n",
        "    min/max value are replaced with np.nan and linearly interpolated with the Pandas interpolate\n",
        "    method.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): Timeseries Data\n",
        "        threshhold (float): Gradient thresshold\n",
        "        iterations (int): number of iterations of the binary dilation\n",
        "        min (float): maximum expected value\n",
        "        max (float): minimum expected value\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: _description_\n",
        "    \"\"\"\n",
        "    gradient = np.diff(data,n=1, axis=0, append=0)\n",
        "    gradientfilter = ndimage.binary_dilation(np.abs(gradient) > threshhold, iterations=iterations)\n",
        "\n",
        "    # Apply Filter\n",
        "    data[gradientfilter] = np.nan\n",
        "\n",
        "    data[data <= min] = np.nan\n",
        "    data[data > max] = np.nan\n",
        "\n",
        "    data = data.interpolate(method = 'linear')\n",
        "    data = data.bfill()\n",
        "    return data\n",
        "\n",
        "### Custom Normalization Functions\n",
        "\n",
        "def NormStandard(dataset: np.array):\n",
        "    mean = np.nanmean(dataset)\n",
        "    std = np.nanstd(dataset)\n",
        "    return (dataset - mean) / std\n",
        "\n",
        "def NormMinMax(dataset: np.array):\n",
        "    min = np.min(dataset)\n",
        "    max = np.max(dataset)\n",
        "    return (dataset - min) / (max - min)\n",
        "\n",
        "def NormCustomBIS(dataset: np.array):\n",
        "    return (100 - dataset) / 100\n",
        "\n",
        "def NormNone(dataset: np.array):\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GDGlya8F4g3h"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class DatasetImport():\n",
        "    def __init__(self, directory: str, dataset: str, vitalpath: str, interval: int = 10):\n",
        "        self.directory = directory\n",
        "        self.datasetpath = directory + dataset\n",
        "        self.vitalpath = directory + vitalpath\n",
        "\n",
        "        self.interval = interval\n",
        "\n",
        "        self.dataset = None\n",
        "        self.validation_dataset = None\n",
        "        self.test_dataset = None\n",
        "\n",
        "        self.index = pd.read_csv(self.datasetpath +'dataset.csv', index_col=0).index.to_numpy()\n",
        "\n",
        "    def save(self, filename: str):\n",
        "        np.savez_compressed(self.datasetpath+filename,\n",
        "                            train = self.train_dataset,\n",
        "                            validation = self.validation_dataset,\n",
        "                            test = self.test_dataset,\n",
        "                            timesteps = self.timesteps,\n",
        "                            )\n",
        "\n",
        "    def load(self, filename: str):\n",
        "        data = np.load(self.datasetpath+filename)\n",
        "        self.train_dataset = data['train']\n",
        "        self.validation_dataset = data['validation']\n",
        "        self.test_dataset = data['test']\n",
        "        try:\n",
        "            self.timesteps = data['timesteps']\n",
        "        except:\n",
        "            self.timesteps = []\n",
        "\n",
        "    def split(self,data):\n",
        "       train, test = train_test_split(data, test_size=0.15, random_state=42)\n",
        "       train, validation = train_test_split(train, test_size=0.15, random_state=42)\n",
        "       return train, validation, test\n",
        "\n",
        "    def generateDataset(self, normalization):\n",
        "\n",
        "        dataset, self.timesteps = self.generate(self.index, normalization)\n",
        "\n",
        "        self.train_dataset, self.validation_dataset, self.test_dataset = self.split(dataset)\n",
        "        print('Dataset succesfully generated                 ')\n",
        "\n",
        "    def generate(self, dataset_index: list, normalization):\n",
        "        batch_list = []\n",
        "        timesteps = []\n",
        "\n",
        "        for i, caseid in enumerate(dataset_index):\n",
        "            filepath = self.vitalpath+str(caseid).zfill(4)+'.vital'\n",
        "            data, importName = self.importFunction(filepath)\n",
        "            timesteps.append(data.shape[0])\n",
        "            batch_list.append(data)\n",
        "            print(importName + \" Fortschritt: %.1f\" % (100 * (i+1) / len(dataset_index)),' % ', end='\\r')\n",
        "\n",
        "        ### Pad the dataset\n",
        "        data = tf.keras.preprocessing.sequence.pad_sequences(batch_list, padding='post', dtype='float32', value=0.0)\n",
        "\n",
        "        # Remove 0.0 padded values\n",
        "        data[data == 0.0] = np.nan\n",
        "\n",
        "        # Nomalization\n",
        "        data = normalization(data)\n",
        "\n",
        "        # restore padded values\n",
        "        np.nan_to_num(data, copy=False, nan=0.0)\n",
        "\n",
        "        return data, np.array(timesteps)\n",
        "\n",
        "    def importFunction(self, filepath: str):\n",
        "        return None, None\n",
        "\n",
        "class infoImport(DatasetImport):\n",
        "    def __init__(self, directory: str, dataset: str, vitalpath: str):\n",
        "        super().__init__(directory,dataset,vitalpath)\n",
        "\n",
        "        self.columns = ['sex','age','height','weight','bmi']\n",
        "\n",
        "    def generate(self, dataset_index: list, normalization):\n",
        "\n",
        "        data = pd.read_csv(self.directory+'info_vitaldb/cases.csv', index_col=0)\n",
        "        data = data[self.columns].loc[dataset_index].to_numpy()\n",
        "\n",
        "        sex = np.where(data[:, 0] == 'F', -0.5, 0.5)\n",
        "\n",
        "        data = data[:,1:].astype(float)\n",
        "        data = np.c_[sex, normalization(data)]\n",
        "\n",
        "        return data, None\n",
        "\n",
        "class VitalImport(DatasetImport):\n",
        "    def __init__(self, directory: str, dataset: str, vitalpath: str):\n",
        "        super().__init__(directory,dataset,vitalpath)\n",
        "\n",
        "        self.tracks = []\n",
        "        self.filter = [0,0,0]\n",
        "        self.name = 'Vital'\n",
        "\n",
        "    def importFunction(self, filepath: str):\n",
        "\n",
        "        vitaldata = vf.VitalFile(ipath = filepath, track_names = self.tracks)\n",
        "\n",
        "        data = vitaldata.to_pandas(track_names=self.tracks,interval=self.interval)\n",
        "        data = data + 0.00001 # adds small value to avoid mix up with padding values\n",
        "        data = outlierfilter(data, threshhold = self.filter[0] , iterations = 2, min = self.filter[1], max = self.filter[2])\n",
        "\n",
        "        return data, self.name\n",
        "\n",
        "class BPImport(DatasetImport):\n",
        "    def __init__(self, directory: str, dataset: str, vitalpath: str):\n",
        "        super().__init__(directory,dataset,vitalpath)\n",
        "\n",
        "    def importFunction(self, filepath: str):\n",
        "        pressureWave = vf.VitalFile(filepath).to_numpy(['SNUADC/ART'], 1/500)\n",
        "\n",
        "        samples = self.interval * 500\n",
        "\n",
        "        # Remove values which derivative is too large\n",
        "        gradient = np.diff(pressureWave,n=1, axis=0, append=0)\n",
        "        gradientfilter1 = ndimage.binary_dilation(np.abs(gradient) > 4,iterations=30)\n",
        "        gradientfilter2 = ndimage.binary_dilation(np.abs(gradient) > 7,iterations=1000)\n",
        "        pressureWave[gradientfilter1] = np.nan\n",
        "        pressureWave[gradientfilter2] = np.nan\n",
        "\n",
        "        # Remove the negative values and values above 250\n",
        "        pressureWave[pressureWave <= 20] = np.nan\n",
        "        pressureWave[pressureWave > 250] = np.nan\n",
        "\n",
        "        pressureWave = self.imputer1.fit_transform(pressureWave)\n",
        "\n",
        "        ### Reshape the pressureWave to 1000 samples (2 seconds) per row\n",
        "        #if (pressureWave.shape[0] % samples) != 0 :\n",
        "        #    steps2fill = samples - (pressureWave.shape[0] % samples)\n",
        "        #    pressureWave = np.pad(array=pressureWave, pad_width=((0,steps2fill),(0,0)), mode='constant', constant_values=np.nan)\n",
        "        length = pressureWave.shape[0] - (pressureWave.shape[0] % samples)\n",
        "        pressureWave = pressureWave[0:length]\n",
        "        return pressureWave.reshape(-1,samples), 'Blood Pressure'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7QPUKpAQ4g3i"
      },
      "outputs": [],
      "source": [
        "###### Create Dataset\n",
        "if create_dataset:\n",
        "    bis = VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    bis.name = 'Bispektralindex'\n",
        "    bis.tracks = ['BIS/BIS']\n",
        "    bis.filter = [20, 10, 100]\n",
        "    bis.generateDataset(normalization=NormCustomBIS)\n",
        "    bis.save('00_bis.npz')\n",
        "\n",
        "    info = infoImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    info.generateDataset(normalization=NormStandard)\n",
        "    info.save('01_info.npz')\n",
        "\n",
        "    bloodpressure = VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    bloodpressure.name = 'bloodpressure'\n",
        "    bloodpressure.tracks = ['Solar8000/ART_DBP', 'Solar8000/ART_MBP', 'Solar8000/ART_SBP']\n",
        "    bloodpressure.filter = [20, 20, 250]\n",
        "    bloodpressure.generateDataset(normalization=NormStandard)\n",
        "    bloodpressure.save('02_bloodpressure.npz')\n",
        "\n",
        "    etCO2 = VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    etCO2.name = 'End Tidal CO2'\n",
        "    etCO2.tracks = ['Primus/ETCO2']\n",
        "    etCO2.filter = [5, 15, 50]\n",
        "    etCO2.generateDataset(normalization=NormStandard)\n",
        "    etCO2.save('02_etCO2.npz')\n",
        "\n",
        "    spO2 = VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    spO2.name = 'SpO2'\n",
        "    spO2.tracks = ['Solar8000/PLETH_SPO2']\n",
        "    spO2.filter = [3, 80, 100]\n",
        "    spO2.generateDataset(normalization=NormStandard)\n",
        "    spO2.save('02_spO2.npz')\n",
        "\n",
        "    hr = VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "    hr.name = 'Heart Rate'\n",
        "    hr.tracks = ['Solar8000/HR']\n",
        "    hr.filter = [20, 40, 180]\n",
        "    hr.generateDataset(normalization=NormStandard)\n",
        "    hr.save('02_hr.npz')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xebtgcoK4g3i"
      },
      "outputs": [],
      "source": [
        "### Load the datasets\n",
        "bis = VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "bis.load('00_bis.npz')\n",
        "\n",
        "info = infoImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "info.load('01_info.npz')\n",
        "\n",
        "bloodpressure = VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "bloodpressure.load('02_bloodpressure.npz')\n",
        "\n",
        "etCO2 = VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "etCO2.load('02_etCO2.npz')\n",
        "\n",
        "spO2 = VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "spO2.load('02_spO2.npz')\n",
        "\n",
        "hr = VitalImport(directory= directory, dataset=datasetpath, vitalpath=vitaldbpath)\n",
        "hr.load('02_hr.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "auUnKLkV4g3j"
      },
      "outputs": [],
      "source": [
        "########################################## COMBINED MODEL ##########################################\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, ReLU, Dropout, Concatenate, Masking, Conv1D, MaxPooling1D, BatchNormalization, RepeatVector\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError, MeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError\n",
        "\n",
        "### Combine the vital data\n",
        "vital_train = np.concatenate([bloodpressure.train_dataset, etCO2.train_dataset, spO2.train_dataset, hr.train_dataset], axis=2)\n",
        "vital_validation = np.concatenate([bloodpressure.validation_dataset, etCO2.validation_dataset, spO2.validation_dataset, hr.validation_dataset], axis=2)\n",
        "vital_test = np.concatenate([bloodpressure.test_dataset, etCO2.test_dataset, spO2.test_dataset, hr.test_dataset], axis=2)\n",
        "\n",
        "y_train = pd.DataFrame(bis.train_dataset[:,:,0].T).rolling(min_periods=1,window=30, center=True).mean().to_numpy().T[:,:,np.newaxis]\n",
        "\n",
        "\n",
        "def simple_model(x_train, y_train, x_val, y_val, params):\n",
        "    ### LSTM layers for the vital data\n",
        "    input_vital = Input(shape=(None, vital_train.shape[2]))\n",
        "    vital_layer = Masking(mask_value=0.0)(input_vital)\n",
        "\n",
        "    ### INFO layers\n",
        "    input_info = Input(shape=(info.train_dataset.shape[1],))\n",
        "    info_layer = RepeatVector(vital_train.shape[1])(input_info)\n",
        "\n",
        "    ## Concatenate the LSTM output with the info layer\n",
        "    comb_layer = Concatenate()([vital_layer, info_layer])\n",
        "    comb_layer = LSTM(units=32, return_sequences=True)(comb_layer)\n",
        "    comb_layer = BatchNormalization()(comb_layer)\n",
        "    comb_layer = LSTM(units=32, return_sequences=True)(comb_layer)\n",
        "    comb_layer = BatchNormalization()(comb_layer)\n",
        "    comb_layer = LSTM(units=32, return_sequences=True)(comb_layer)\n",
        "    comb_layer = BatchNormalization()(comb_layer)\n",
        "    comb_layer = Dense(units=128, activation='relu')(comb_layer)\n",
        "    comb_layer = BatchNormalization()(comb_layer)\n",
        "    comb_layer = Dense(units=32, activation='relu')(comb_layer)\n",
        "    comb_layer = BatchNormalization()(comb_layer)\n",
        "\n",
        "\n",
        "    output = Dense(units=1)(comb_layer)\n",
        "    output = ReLU(max_value=1.0)(output)\n",
        "\n",
        "    # Define the model\n",
        "    model = Model(inputs=[input_vital, input_info], outputs=output)\n",
        "\n",
        "    # Compile the model\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                loss=tf.keras.losses.MeanSquaredError(),\n",
        "                metrics=['MeanSquaredError','MeanAbsoluteError']\n",
        "                )\n",
        "\n",
        "    #model.summary()\n",
        "\n",
        "\n",
        "    # Train the model\n",
        "    out = model.fit(x_train,\n",
        "                        y_train,\n",
        "                        validation_data=[x_val, y_val],\n",
        "                        epochs=30,\n",
        "                        batch_size=params['batch_size']\n",
        "                        )\n",
        "    return out, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Tdl4u7SZsk9i",
        "outputId": "b2c4dda6-1a01-430d-c0ab-387f4ff461c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, None, 6)]            0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 5)]                  0         []                            \n",
            "                                                                                                  \n",
            " masking (Masking)           (None, None, 6)              0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " repeat_vector (RepeatVecto  (None, 3680, 5)              0         ['input_2[0][0]']             \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 3680, 11)             0         ['masking[0][0]',             \n",
            "                                                                     'repeat_vector[0][0]']       \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 (None, 3680, 32)             5632      ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 3680, 32)             128       ['lstm[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               (None, 3680, 32)             8320      ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 3680, 32)             128       ['lstm_1[0][0]']              \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               (None, 3680, 32)             8320      ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 3680, 32)             128       ['lstm_2[0][0]']              \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 3680, 128)            4224      ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 3680, 128)            512       ['dense[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 3680, 32)             4128      ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 3680, 32)             128       ['dense_1[0][0]']             \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 3680, 1)              33        ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                (None, 3680, 1)              0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31681 (123.75 KB)\n",
            "Trainable params: 31169 (121.75 KB)\n",
            "Non-trainable params: 512 (2.00 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "56/56 [==============================] - 41s 228ms/step - loss: 0.1993 - mean_squared_error: 0.2021 - mean_absolute_error: 0.4036 - val_loss: 0.1002 - val_mean_squared_error: 0.0969 - val_mean_absolute_error: 0.2867\n",
            "Epoch 2/30\n",
            "56/56 [==============================] - 9s 170ms/step - loss: 0.1097 - mean_squared_error: 0.1101 - mean_absolute_error: 0.2713 - val_loss: 0.0597 - val_mean_squared_error: 0.0580 - val_mean_absolute_error: 0.2090\n",
            "Epoch 3/30\n",
            "56/56 [==============================] - 8s 151ms/step - loss: 0.0529 - mean_squared_error: 0.0539 - mean_absolute_error: 0.1802 - val_loss: 0.0259 - val_mean_squared_error: 0.0256 - val_mean_absolute_error: 0.1244\n",
            "Epoch 4/30\n",
            "56/56 [==============================] - 10s 173ms/step - loss: 0.0300 - mean_squared_error: 0.0299 - mean_absolute_error: 0.1303 - val_loss: 0.0238 - val_mean_squared_error: 0.0233 - val_mean_absolute_error: 0.1155\n",
            "Epoch 5/30\n",
            "56/56 [==============================] - 9s 168ms/step - loss: 0.0228 - mean_squared_error: 0.0227 - mean_absolute_error: 0.1135 - val_loss: 0.0263 - val_mean_squared_error: 0.0259 - val_mean_absolute_error: 0.1240\n",
            "Epoch 6/30\n",
            "56/56 [==============================] - 9s 160ms/step - loss: 0.0203 - mean_squared_error: 0.0199 - mean_absolute_error: 0.1058 - val_loss: 0.0201 - val_mean_squared_error: 0.0198 - val_mean_absolute_error: 0.1013\n",
            "Epoch 7/30\n",
            "56/56 [==============================] - 10s 172ms/step - loss: 0.0175 - mean_squared_error: 0.0174 - mean_absolute_error: 0.0984 - val_loss: 0.0195 - val_mean_squared_error: 0.0194 - val_mean_absolute_error: 0.1027\n",
            "Epoch 8/30\n",
            "56/56 [==============================] - 9s 169ms/step - loss: 0.0165 - mean_squared_error: 0.0162 - mean_absolute_error: 0.0944 - val_loss: 0.0206 - val_mean_squared_error: 0.0201 - val_mean_absolute_error: 0.1042\n",
            "Epoch 9/30\n",
            "56/56 [==============================] - 9s 168ms/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0939 - val_loss: 0.0190 - val_mean_squared_error: 0.0184 - val_mean_absolute_error: 0.1005\n",
            "Epoch 10/30\n",
            "56/56 [==============================] - 9s 154ms/step - loss: 0.0161 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0945 - val_loss: 0.0211 - val_mean_squared_error: 0.0204 - val_mean_absolute_error: 0.1036\n",
            "Epoch 11/30\n",
            "56/56 [==============================] - 10s 172ms/step - loss: 0.0147 - mean_squared_error: 0.0143 - mean_absolute_error: 0.0888 - val_loss: 0.0216 - val_mean_squared_error: 0.0201 - val_mean_absolute_error: 0.1055\n",
            "Epoch 12/30\n",
            "56/56 [==============================] - 10s 183ms/step - loss: 0.0144 - mean_squared_error: 0.0140 - mean_absolute_error: 0.0885 - val_loss: 0.0225 - val_mean_squared_error: 0.0215 - val_mean_absolute_error: 0.1130\n",
            "Epoch 13/30\n",
            "56/56 [==============================] - 10s 175ms/step - loss: 0.0136 - mean_squared_error: 0.0135 - mean_absolute_error: 0.0872 - val_loss: 0.0221 - val_mean_squared_error: 0.0209 - val_mean_absolute_error: 0.1078\n",
            "Epoch 14/30\n",
            "56/56 [==============================] - 9s 155ms/step - loss: 0.0135 - mean_squared_error: 0.0134 - mean_absolute_error: 0.0869 - val_loss: 0.0200 - val_mean_squared_error: 0.0190 - val_mean_absolute_error: 0.1047\n",
            "Epoch 15/30\n",
            "56/56 [==============================] - 10s 171ms/step - loss: 0.0134 - mean_squared_error: 0.0132 - mean_absolute_error: 0.0862 - val_loss: 0.0196 - val_mean_squared_error: 0.0187 - val_mean_absolute_error: 0.1022\n",
            "Epoch 16/30\n",
            "56/56 [==============================] - 10s 171ms/step - loss: 0.0129 - mean_squared_error: 0.0130 - mean_absolute_error: 0.0848 - val_loss: 0.0200 - val_mean_squared_error: 0.0195 - val_mean_absolute_error: 0.1022\n",
            "Epoch 17/30\n",
            "56/56 [==============================] - 9s 152ms/step - loss: 0.0129 - mean_squared_error: 0.0124 - mean_absolute_error: 0.0827 - val_loss: 0.0199 - val_mean_squared_error: 0.0194 - val_mean_absolute_error: 0.1018\n",
            "Epoch 18/30\n",
            "56/56 [==============================] - 10s 172ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - mean_absolute_error: 0.0827 - val_loss: 0.0208 - val_mean_squared_error: 0.0199 - val_mean_absolute_error: 0.1024\n",
            "Epoch 19/30\n",
            "56/56 [==============================] - 10s 171ms/step - loss: 0.0125 - mean_squared_error: 0.0122 - mean_absolute_error: 0.0825 - val_loss: 0.0194 - val_mean_squared_error: 0.0187 - val_mean_absolute_error: 0.1034\n",
            "Epoch 20/30\n",
            "56/56 [==============================] - 9s 154ms/step - loss: 0.0122 - mean_squared_error: 0.0119 - mean_absolute_error: 0.0815 - val_loss: 0.0206 - val_mean_squared_error: 0.0195 - val_mean_absolute_error: 0.1036\n",
            "Epoch 21/30\n",
            "56/56 [==============================] - 9s 166ms/step - loss: 0.0126 - mean_squared_error: 0.0124 - mean_absolute_error: 0.0836 - val_loss: 0.0205 - val_mean_squared_error: 0.0194 - val_mean_absolute_error: 0.1001\n",
            "Epoch 22/30\n",
            "56/56 [==============================] - 9s 165ms/step - loss: 0.0120 - mean_squared_error: 0.0117 - mean_absolute_error: 0.0802 - val_loss: 0.0211 - val_mean_squared_error: 0.0199 - val_mean_absolute_error: 0.1008\n",
            "Epoch 23/30\n",
            "56/56 [==============================] - 9s 168ms/step - loss: 0.0116 - mean_squared_error: 0.0115 - mean_absolute_error: 0.0800 - val_loss: 0.0257 - val_mean_squared_error: 0.0225 - val_mean_absolute_error: 0.1097\n",
            "Epoch 24/30\n",
            "56/56 [==============================] - 9s 155ms/step - loss: 0.0122 - mean_squared_error: 0.0119 - mean_absolute_error: 0.0814 - val_loss: 0.0266 - val_mean_squared_error: 0.0238 - val_mean_absolute_error: 0.1114\n",
            "Epoch 25/30\n",
            "56/56 [==============================] - 10s 172ms/step - loss: 0.0116 - mean_squared_error: 0.0114 - mean_absolute_error: 0.0795 - val_loss: 0.0288 - val_mean_squared_error: 0.0261 - val_mean_absolute_error: 0.1128\n",
            "Epoch 26/30\n",
            "56/56 [==============================] - 10s 171ms/step - loss: 0.0112 - mean_squared_error: 0.0111 - mean_absolute_error: 0.0794 - val_loss: 0.0236 - val_mean_squared_error: 0.0210 - val_mean_absolute_error: 0.1040\n",
            "Epoch 27/30\n",
            "56/56 [==============================] - 8s 151ms/step - loss: 0.0112 - mean_squared_error: 0.0109 - mean_absolute_error: 0.0785 - val_loss: 0.0238 - val_mean_squared_error: 0.0217 - val_mean_absolute_error: 0.1071\n",
            "Epoch 28/30\n",
            "56/56 [==============================] - 9s 169ms/step - loss: 0.0115 - mean_squared_error: 0.0112 - mean_absolute_error: 0.0794 - val_loss: 0.0223 - val_mean_squared_error: 0.0206 - val_mean_absolute_error: 0.1014\n",
            "Epoch 29/30\n",
            "56/56 [==============================] - 10s 170ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - mean_absolute_error: 0.0792 - val_loss: 0.0260 - val_mean_squared_error: 0.0232 - val_mean_absolute_error: 0.1135\n",
            "Epoch 30/30\n",
            "56/56 [==============================] - 9s 161ms/step - loss: 0.0116 - mean_squared_error: 0.0113 - mean_absolute_error: 0.0801 - val_loss: 0.0255 - val_mean_squared_error: 0.0223 - val_mean_absolute_error: 0.1099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 1/5 [05:54<23:38, 354.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, None, 6)]            0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 5)]                  0         []                            \n",
            "                                                                                                  \n",
            " masking (Masking)           (None, None, 6)              0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " repeat_vector (RepeatVecto  (None, 3680, 5)              0         ['input_2[0][0]']             \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 3680, 11)             0         ['masking[0][0]',             \n",
            "                                                                     'repeat_vector[0][0]']       \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 (None, 3680, 32)             5632      ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 3680, 32)             128       ['lstm[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               (None, 3680, 32)             8320      ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 3680, 32)             128       ['lstm_1[0][0]']              \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               (None, 3680, 32)             8320      ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 3680, 32)             128       ['lstm_2[0][0]']              \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 3680, 128)            4224      ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 3680, 128)            512       ['dense[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 3680, 32)             4128      ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 3680, 32)             128       ['dense_1[0][0]']             \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 3680, 1)              33        ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                (None, 3680, 1)              0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31681 (123.75 KB)\n",
            "Trainable params: 31169 (121.75 KB)\n",
            "Non-trainable params: 512 (2.00 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "28/28 [==============================] - 23s 275ms/step - loss: 0.2145 - mean_squared_error: 0.2171 - mean_absolute_error: 0.4299 - val_loss: 0.0773 - val_mean_squared_error: 0.0779 - val_mean_absolute_error: 0.2609\n",
            "Epoch 2/30\n",
            "28/28 [==============================] - 6s 222ms/step - loss: 0.1636 - mean_squared_error: 0.1647 - mean_absolute_error: 0.3541 - val_loss: 0.0306 - val_mean_squared_error: 0.0309 - val_mean_absolute_error: 0.1427\n",
            "Epoch 3/30\n",
            "28/28 [==============================] - 5s 189ms/step - loss: 0.0964 - mean_squared_error: 0.0975 - mean_absolute_error: 0.2493 - val_loss: 0.0286 - val_mean_squared_error: 0.0287 - val_mean_absolute_error: 0.1272\n",
            "Epoch 4/30\n",
            "28/28 [==============================] - 6s 206ms/step - loss: 0.0571 - mean_squared_error: 0.0568 - mean_absolute_error: 0.1777 - val_loss: 0.0316 - val_mean_squared_error: 0.0317 - val_mean_absolute_error: 0.1353\n",
            "Epoch 5/30\n",
            "28/28 [==============================] - 6s 193ms/step - loss: 0.0367 - mean_squared_error: 0.0363 - mean_absolute_error: 0.1383 - val_loss: 0.0363 - val_mean_squared_error: 0.0364 - val_mean_absolute_error: 0.1481\n",
            "Epoch 6/30\n",
            "28/28 [==============================] - 5s 193ms/step - loss: 0.0282 - mean_squared_error: 0.0282 - mean_absolute_error: 0.1229 - val_loss: 0.0282 - val_mean_squared_error: 0.0281 - val_mean_absolute_error: 0.1238\n",
            "Epoch 7/30\n",
            "28/28 [==============================] - 6s 211ms/step - loss: 0.0218 - mean_squared_error: 0.0214 - mean_absolute_error: 0.1081 - val_loss: 0.0273 - val_mean_squared_error: 0.0274 - val_mean_absolute_error: 0.1199\n",
            "Epoch 8/30\n",
            "28/28 [==============================] - 5s 180ms/step - loss: 0.0209 - mean_squared_error: 0.0209 - mean_absolute_error: 0.1062 - val_loss: 0.0250 - val_mean_squared_error: 0.0252 - val_mean_absolute_error: 0.1166\n",
            "Epoch 9/30\n",
            "28/28 [==============================] - 6s 212ms/step - loss: 0.0204 - mean_squared_error: 0.0201 - mean_absolute_error: 0.1035 - val_loss: 0.0213 - val_mean_squared_error: 0.0211 - val_mean_absolute_error: 0.1030\n",
            "Epoch 10/30\n",
            "28/28 [==============================] - 5s 182ms/step - loss: 0.0169 - mean_squared_error: 0.0169 - mean_absolute_error: 0.0960 - val_loss: 0.0194 - val_mean_squared_error: 0.0195 - val_mean_absolute_error: 0.0971\n",
            "Epoch 11/30\n",
            "28/28 [==============================] - 5s 196ms/step - loss: 0.0159 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0903 - val_loss: 0.0176 - val_mean_squared_error: 0.0177 - val_mean_absolute_error: 0.0931\n",
            "Epoch 12/30\n",
            "28/28 [==============================] - 5s 190ms/step - loss: 0.0158 - mean_squared_error: 0.0159 - mean_absolute_error: 0.0924 - val_loss: 0.0175 - val_mean_squared_error: 0.0175 - val_mean_absolute_error: 0.0938\n",
            "Epoch 13/30\n",
            "28/28 [==============================] - 5s 187ms/step - loss: 0.0159 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0918 - val_loss: 0.0175 - val_mean_squared_error: 0.0174 - val_mean_absolute_error: 0.0965\n",
            "Epoch 14/30\n",
            "28/28 [==============================] - 6s 226ms/step - loss: 0.0156 - mean_squared_error: 0.0153 - mean_absolute_error: 0.0893 - val_loss: 0.0174 - val_mean_squared_error: 0.0173 - val_mean_absolute_error: 0.0960\n",
            "Epoch 15/30\n",
            "28/28 [==============================] - 5s 193ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - mean_absolute_error: 0.0889 - val_loss: 0.0175 - val_mean_squared_error: 0.0173 - val_mean_absolute_error: 0.0956\n",
            "Epoch 16/30\n",
            "28/28 [==============================] - 6s 226ms/step - loss: 0.0142 - mean_squared_error: 0.0141 - mean_absolute_error: 0.0853 - val_loss: 0.0183 - val_mean_squared_error: 0.0181 - val_mean_absolute_error: 0.1031\n",
            "Epoch 17/30\n",
            "28/28 [==============================] - 5s 193ms/step - loss: 0.0146 - mean_squared_error: 0.0144 - mean_absolute_error: 0.0885 - val_loss: 0.0190 - val_mean_squared_error: 0.0189 - val_mean_absolute_error: 0.1051\n",
            "Epoch 18/30\n",
            "28/28 [==============================] - 6s 226ms/step - loss: 0.0139 - mean_squared_error: 0.0138 - mean_absolute_error: 0.0857 - val_loss: 0.0177 - val_mean_squared_error: 0.0175 - val_mean_absolute_error: 0.0981\n",
            "Epoch 19/30\n",
            "28/28 [==============================] - 5s 189ms/step - loss: 0.0134 - mean_squared_error: 0.0132 - mean_absolute_error: 0.0841 - val_loss: 0.0179 - val_mean_squared_error: 0.0178 - val_mean_absolute_error: 0.0978\n",
            "Epoch 20/30\n",
            "28/28 [==============================] - 6s 211ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - mean_absolute_error: 0.0826 - val_loss: 0.0189 - val_mean_squared_error: 0.0184 - val_mean_absolute_error: 0.1019\n",
            "Epoch 21/30\n",
            "28/28 [==============================] - 6s 202ms/step - loss: 0.0134 - mean_squared_error: 0.0131 - mean_absolute_error: 0.0832 - val_loss: 0.0188 - val_mean_squared_error: 0.0185 - val_mean_absolute_error: 0.1030\n",
            "Epoch 22/30\n",
            "28/28 [==============================] - 5s 192ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - mean_absolute_error: 0.0840 - val_loss: 0.0175 - val_mean_squared_error: 0.0172 - val_mean_absolute_error: 0.0980\n",
            "Epoch 23/30\n",
            "28/28 [==============================] - 6s 223ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - mean_absolute_error: 0.0840 - val_loss: 0.0165 - val_mean_squared_error: 0.0166 - val_mean_absolute_error: 0.0943\n",
            "Epoch 24/30\n",
            "28/28 [==============================] - 5s 190ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - mean_absolute_error: 0.0812 - val_loss: 0.0176 - val_mean_squared_error: 0.0174 - val_mean_absolute_error: 0.0999\n",
            "Epoch 25/30\n",
            "28/28 [==============================] - 6s 213ms/step - loss: 0.0129 - mean_squared_error: 0.0128 - mean_absolute_error: 0.0844 - val_loss: 0.0172 - val_mean_squared_error: 0.0170 - val_mean_absolute_error: 0.0974\n",
            "Epoch 26/30\n",
            "28/28 [==============================] - 5s 183ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - mean_absolute_error: 0.0814 - val_loss: 0.0183 - val_mean_squared_error: 0.0180 - val_mean_absolute_error: 0.1003\n",
            "Epoch 27/30\n",
            "28/28 [==============================] - 6s 223ms/step - loss: 0.0127 - mean_squared_error: 0.0126 - mean_absolute_error: 0.0832 - val_loss: 0.0187 - val_mean_squared_error: 0.0187 - val_mean_absolute_error: 0.1010\n",
            "Epoch 28/30\n",
            "28/28 [==============================] - 5s 187ms/step - loss: 0.0121 - mean_squared_error: 0.0122 - mean_absolute_error: 0.0804 - val_loss: 0.0180 - val_mean_squared_error: 0.0176 - val_mean_absolute_error: 0.0983\n",
            "Epoch 29/30\n",
            "28/28 [==============================] - 5s 186ms/step - loss: 0.0117 - mean_squared_error: 0.0116 - mean_absolute_error: 0.0792 - val_loss: 0.0182 - val_mean_squared_error: 0.0180 - val_mean_absolute_error: 0.0979\n",
            "Epoch 30/30\n",
            "28/28 [==============================] - 6s 210ms/step - loss: 0.0118 - mean_squared_error: 0.0117 - mean_absolute_error: 0.0788 - val_loss: 0.0190 - val_mean_squared_error: 0.0186 - val_mean_absolute_error: 0.1026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [09:04<12:52, 257.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, None, 6)]            0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 5)]                  0         []                            \n",
            "                                                                                                  \n",
            " masking (Masking)           (None, None, 6)              0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " repeat_vector (RepeatVecto  (None, 3680, 5)              0         ['input_2[0][0]']             \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 3680, 11)             0         ['masking[0][0]',             \n",
            "                                                                     'repeat_vector[0][0]']       \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 (None, 3680, 32)             5632      ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 3680, 32)             128       ['lstm[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               (None, 3680, 32)             8320      ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 3680, 32)             128       ['lstm_1[0][0]']              \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               (None, 3680, 32)             8320      ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 3680, 32)             128       ['lstm_2[0][0]']              \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 3680, 128)            4224      ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 3680, 128)            512       ['dense[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 3680, 32)             4128      ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 3680, 32)             128       ['dense_1[0][0]']             \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 3680, 1)              33        ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                (None, 3680, 1)              0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31681 (123.75 KB)\n",
            "Trainable params: 31169 (121.75 KB)\n",
            "Non-trainable params: 512 (2.00 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "14/14 [==============================] - 23s 564ms/step - loss: 0.2195 - mean_squared_error: 0.2202 - mean_absolute_error: 0.4263 - val_loss: 0.2695 - val_mean_squared_error: 0.2689 - val_mean_absolute_error: 0.5009\n",
            "Epoch 2/30\n",
            "14/14 [==============================] - 3s 224ms/step - loss: 0.1773 - mean_squared_error: 0.1773 - mean_absolute_error: 0.3725 - val_loss: 0.2337 - val_mean_squared_error: 0.2333 - val_mean_absolute_error: 0.4640\n",
            "Epoch 3/30\n",
            "14/14 [==============================] - 3s 222ms/step - loss: 0.1340 - mean_squared_error: 0.1337 - mean_absolute_error: 0.3092 - val_loss: 0.1784 - val_mean_squared_error: 0.1779 - val_mean_absolute_error: 0.4031\n",
            "Epoch 4/30\n",
            "14/14 [==============================] - 4s 278ms/step - loss: 0.0971 - mean_squared_error: 0.0973 - mean_absolute_error: 0.2537 - val_loss: 0.1628 - val_mean_squared_error: 0.1625 - val_mean_absolute_error: 0.3809\n",
            "Epoch 5/30\n",
            "14/14 [==============================] - 3s 216ms/step - loss: 0.0730 - mean_squared_error: 0.0730 - mean_absolute_error: 0.2110 - val_loss: 0.1241 - val_mean_squared_error: 0.1242 - val_mean_absolute_error: 0.3288\n",
            "Epoch 6/30\n",
            "14/14 [==============================] - 3s 222ms/step - loss: 0.0556 - mean_squared_error: 0.0547 - mean_absolute_error: 0.1779 - val_loss: 0.1062 - val_mean_squared_error: 0.1064 - val_mean_absolute_error: 0.3028\n",
            "Epoch 7/30\n",
            "14/14 [==============================] - 3s 219ms/step - loss: 0.0429 - mean_squared_error: 0.0423 - mean_absolute_error: 0.1560 - val_loss: 0.0845 - val_mean_squared_error: 0.0847 - val_mean_absolute_error: 0.2671\n",
            "Epoch 8/30\n",
            "14/14 [==============================] - 4s 257ms/step - loss: 0.0335 - mean_squared_error: 0.0333 - mean_absolute_error: 0.1369 - val_loss: 0.0742 - val_mean_squared_error: 0.0743 - val_mean_absolute_error: 0.2501\n",
            "Epoch 9/30\n",
            "14/14 [==============================] - 3s 219ms/step - loss: 0.0294 - mean_squared_error: 0.0293 - mean_absolute_error: 0.1284 - val_loss: 0.0670 - val_mean_squared_error: 0.0672 - val_mean_absolute_error: 0.2355\n",
            "Epoch 10/30\n",
            "14/14 [==============================] - 3s 214ms/step - loss: 0.0258 - mean_squared_error: 0.0253 - mean_absolute_error: 0.1195 - val_loss: 0.0557 - val_mean_squared_error: 0.0559 - val_mean_absolute_error: 0.2142\n",
            "Epoch 11/30\n",
            "14/14 [==============================] - 3s 218ms/step - loss: 0.0224 - mean_squared_error: 0.0223 - mean_absolute_error: 0.1104 - val_loss: 0.0441 - val_mean_squared_error: 0.0442 - val_mean_absolute_error: 0.1885\n",
            "Epoch 12/30\n",
            "14/14 [==============================] - 4s 272ms/step - loss: 0.0203 - mean_squared_error: 0.0204 - mean_absolute_error: 0.1062 - val_loss: 0.0425 - val_mean_squared_error: 0.0427 - val_mean_absolute_error: 0.1827\n",
            "Epoch 13/30\n",
            "14/14 [==============================] - 3s 216ms/step - loss: 0.0202 - mean_squared_error: 0.0201 - mean_absolute_error: 0.1050 - val_loss: 0.0364 - val_mean_squared_error: 0.0364 - val_mean_absolute_error: 0.1675\n",
            "Epoch 14/30\n",
            "14/14 [==============================] - 3s 217ms/step - loss: 0.0184 - mean_squared_error: 0.0183 - mean_absolute_error: 0.0994 - val_loss: 0.0342 - val_mean_squared_error: 0.0342 - val_mean_absolute_error: 0.1618\n",
            "Epoch 15/30\n",
            "14/14 [==============================] - 3s 241ms/step - loss: 0.0184 - mean_squared_error: 0.0179 - mean_absolute_error: 0.0983 - val_loss: 0.0276 - val_mean_squared_error: 0.0275 - val_mean_absolute_error: 0.1399\n",
            "Epoch 16/30\n",
            "14/14 [==============================] - 4s 254ms/step - loss: 0.0171 - mean_squared_error: 0.0169 - mean_absolute_error: 0.0961 - val_loss: 0.0261 - val_mean_squared_error: 0.0261 - val_mean_absolute_error: 0.1345\n",
            "Epoch 17/30\n",
            "14/14 [==============================] - 3s 220ms/step - loss: 0.0164 - mean_squared_error: 0.0162 - mean_absolute_error: 0.0938 - val_loss: 0.0281 - val_mean_squared_error: 0.0281 - val_mean_absolute_error: 0.1398\n",
            "Epoch 18/30\n",
            "14/14 [==============================] - 3s 221ms/step - loss: 0.0153 - mean_squared_error: 0.0152 - mean_absolute_error: 0.0910 - val_loss: 0.0266 - val_mean_squared_error: 0.0266 - val_mean_absolute_error: 0.1330\n",
            "Epoch 19/30\n",
            "14/14 [==============================] - 4s 262ms/step - loss: 0.0149 - mean_squared_error: 0.0149 - mean_absolute_error: 0.0896 - val_loss: 0.0218 - val_mean_squared_error: 0.0217 - val_mean_absolute_error: 0.1179\n",
            "Epoch 20/30\n",
            "14/14 [==============================] - 4s 252ms/step - loss: 0.0146 - mean_squared_error: 0.0145 - mean_absolute_error: 0.0889 - val_loss: 0.0220 - val_mean_squared_error: 0.0219 - val_mean_absolute_error: 0.1193\n",
            "Epoch 21/30\n",
            "14/14 [==============================] - 3s 223ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - mean_absolute_error: 0.0895 - val_loss: 0.0206 - val_mean_squared_error: 0.0206 - val_mean_absolute_error: 0.1121\n",
            "Epoch 22/30\n",
            "14/14 [==============================] - 3s 215ms/step - loss: 0.0142 - mean_squared_error: 0.0140 - mean_absolute_error: 0.0875 - val_loss: 0.0207 - val_mean_squared_error: 0.0206 - val_mean_absolute_error: 0.1106\n",
            "Epoch 23/30\n",
            "14/14 [==============================] - 3s 239ms/step - loss: 0.0141 - mean_squared_error: 0.0140 - mean_absolute_error: 0.0865 - val_loss: 0.0189 - val_mean_squared_error: 0.0188 - val_mean_absolute_error: 0.1024\n",
            "Epoch 24/30\n",
            "14/14 [==============================] - 3s 243ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - mean_absolute_error: 0.0856 - val_loss: 0.0172 - val_mean_squared_error: 0.0171 - val_mean_absolute_error: 0.0974\n",
            "Epoch 25/30\n",
            "14/14 [==============================] - 3s 220ms/step - loss: 0.0135 - mean_squared_error: 0.0133 - mean_absolute_error: 0.0841 - val_loss: 0.0183 - val_mean_squared_error: 0.0182 - val_mean_absolute_error: 0.0988\n",
            "Epoch 26/30\n",
            "14/14 [==============================] - 3s 212ms/step - loss: 0.0128 - mean_squared_error: 0.0127 - mean_absolute_error: 0.0827 - val_loss: 0.0180 - val_mean_squared_error: 0.0179 - val_mean_absolute_error: 0.0975\n",
            "Epoch 27/30\n",
            "14/14 [==============================] - 4s 266ms/step - loss: 0.0133 - mean_squared_error: 0.0131 - mean_absolute_error: 0.0846 - val_loss: 0.0167 - val_mean_squared_error: 0.0165 - val_mean_absolute_error: 0.0939\n",
            "Epoch 28/30\n",
            "14/14 [==============================] - 3s 244ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - mean_absolute_error: 0.0847 - val_loss: 0.0169 - val_mean_squared_error: 0.0168 - val_mean_absolute_error: 0.0926\n",
            "Epoch 29/30\n",
            "14/14 [==============================] - 3s 213ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - mean_absolute_error: 0.0859 - val_loss: 0.0166 - val_mean_squared_error: 0.0164 - val_mean_absolute_error: 0.0911\n",
            "Epoch 30/30\n",
            "14/14 [==============================] - 3s 214ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - mean_absolute_error: 0.0816 - val_loss: 0.0170 - val_mean_squared_error: 0.0168 - val_mean_absolute_error: 0.0926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [11:41<07:03, 211.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, None, 6)]            0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 5)]                  0         []                            \n",
            "                                                                                                  \n",
            " masking (Masking)           (None, None, 6)              0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " repeat_vector (RepeatVecto  (None, 3680, 5)              0         ['input_2[0][0]']             \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 3680, 11)             0         ['masking[0][0]',             \n",
            "                                                                     'repeat_vector[0][0]']       \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 (None, 3680, 32)             5632      ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 3680, 32)             128       ['lstm[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               (None, 3680, 32)             8320      ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 3680, 32)             128       ['lstm_1[0][0]']              \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               (None, 3680, 32)             8320      ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 3680, 32)             128       ['lstm_2[0][0]']              \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 3680, 128)            4224      ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 3680, 128)            512       ['dense[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 3680, 32)             4128      ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 3680, 32)             128       ['dense_1[0][0]']             \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 3680, 1)              33        ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                (None, 3680, 1)              0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31681 (123.75 KB)\n",
            "Trainable params: 31169 (121.75 KB)\n",
            "Non-trainable params: 512 (2.00 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "7/7 [==============================] - 21s 987ms/step - loss: 0.2330 - mean_squared_error: 0.2332 - mean_absolute_error: 0.4501 - val_loss: 0.2510 - val_mean_squared_error: 0.2514 - val_mean_absolute_error: 0.4848\n",
            "Epoch 2/30\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.2046 - mean_squared_error: 0.2037 - mean_absolute_error: 0.4145 - val_loss: 0.1802 - val_mean_squared_error: 0.1806 - val_mean_absolute_error: 0.4079\n",
            "Epoch 3/30\n",
            "7/7 [==============================] - 2s 244ms/step - loss: 0.1815 - mean_squared_error: 0.1817 - mean_absolute_error: 0.3858 - val_loss: 0.1503 - val_mean_squared_error: 0.1506 - val_mean_absolute_error: 0.3709\n",
            "Epoch 4/30\n",
            "7/7 [==============================] - 2s 256ms/step - loss: 0.1541 - mean_squared_error: 0.1543 - mean_absolute_error: 0.3428 - val_loss: 0.1241 - val_mean_squared_error: 0.1244 - val_mean_absolute_error: 0.3353\n",
            "Epoch 5/30\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 0.1270 - mean_squared_error: 0.1270 - mean_absolute_error: 0.3007 - val_loss: 0.1040 - val_mean_squared_error: 0.1042 - val_mean_absolute_error: 0.3054\n",
            "Epoch 6/30\n",
            "7/7 [==============================] - 2s 271ms/step - loss: 0.1031 - mean_squared_error: 0.1026 - mean_absolute_error: 0.2598 - val_loss: 0.0806 - val_mean_squared_error: 0.0808 - val_mean_absolute_error: 0.2659\n",
            "Epoch 7/30\n",
            "7/7 [==============================] - 2s 257ms/step - loss: 0.0901 - mean_squared_error: 0.0901 - mean_absolute_error: 0.2411 - val_loss: 0.0640 - val_mean_squared_error: 0.0642 - val_mean_absolute_error: 0.2312\n",
            "Epoch 8/30\n",
            "7/7 [==============================] - 2s 287ms/step - loss: 0.0763 - mean_squared_error: 0.0765 - mean_absolute_error: 0.2173 - val_loss: 0.0468 - val_mean_squared_error: 0.0469 - val_mean_absolute_error: 0.1940\n",
            "Epoch 9/30\n",
            "7/7 [==============================] - 2s 334ms/step - loss: 0.0624 - mean_squared_error: 0.0622 - mean_absolute_error: 0.1894 - val_loss: 0.0391 - val_mean_squared_error: 0.0392 - val_mean_absolute_error: 0.1742\n",
            "Epoch 10/30\n",
            "7/7 [==============================] - 2s 267ms/step - loss: 0.0528 - mean_squared_error: 0.0524 - mean_absolute_error: 0.1709 - val_loss: 0.0351 - val_mean_squared_error: 0.0352 - val_mean_absolute_error: 0.1625\n",
            "Epoch 11/30\n",
            "7/7 [==============================] - 2s 271ms/step - loss: 0.0484 - mean_squared_error: 0.0483 - mean_absolute_error: 0.1648 - val_loss: 0.0321 - val_mean_squared_error: 0.0322 - val_mean_absolute_error: 0.1535\n",
            "Epoch 12/30\n",
            "7/7 [==============================] - 2s 281ms/step - loss: 0.0416 - mean_squared_error: 0.0414 - mean_absolute_error: 0.1504 - val_loss: 0.0267 - val_mean_squared_error: 0.0267 - val_mean_absolute_error: 0.1345\n",
            "Epoch 13/30\n",
            "7/7 [==============================] - 2s 279ms/step - loss: 0.0373 - mean_squared_error: 0.0372 - mean_absolute_error: 0.1424 - val_loss: 0.0249 - val_mean_squared_error: 0.0250 - val_mean_absolute_error: 0.1285\n",
            "Epoch 14/30\n",
            "7/7 [==============================] - 2s 283ms/step - loss: 0.0351 - mean_squared_error: 0.0353 - mean_absolute_error: 0.1385 - val_loss: 0.0253 - val_mean_squared_error: 0.0254 - val_mean_absolute_error: 0.1297\n",
            "Epoch 15/30\n",
            "7/7 [==============================] - 3s 379ms/step - loss: 0.0330 - mean_squared_error: 0.0328 - mean_absolute_error: 0.1342 - val_loss: 0.0250 - val_mean_squared_error: 0.0250 - val_mean_absolute_error: 0.1279\n",
            "Epoch 16/30\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 0.0282 - mean_squared_error: 0.0281 - mean_absolute_error: 0.1216 - val_loss: 0.0249 - val_mean_squared_error: 0.0250 - val_mean_absolute_error: 0.1276\n",
            "Epoch 17/30\n",
            "7/7 [==============================] - 2s 281ms/step - loss: 0.0286 - mean_squared_error: 0.0286 - mean_absolute_error: 0.1253 - val_loss: 0.0244 - val_mean_squared_error: 0.0244 - val_mean_absolute_error: 0.1250\n",
            "Epoch 18/30\n",
            "7/7 [==============================] - 2s 282ms/step - loss: 0.0265 - mean_squared_error: 0.0263 - mean_absolute_error: 0.1192 - val_loss: 0.0245 - val_mean_squared_error: 0.0245 - val_mean_absolute_error: 0.1253\n",
            "Epoch 19/30\n",
            "7/7 [==============================] - 2s 248ms/step - loss: 0.0266 - mean_squared_error: 0.0265 - mean_absolute_error: 0.1182 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1203\n",
            "Epoch 20/30\n",
            "7/7 [==============================] - 2s 247ms/step - loss: 0.0252 - mean_squared_error: 0.0248 - mean_absolute_error: 0.1166 - val_loss: 0.0236 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.1203\n",
            "Epoch 21/30\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0270 - mean_squared_error: 0.0269 - mean_absolute_error: 0.1205 - val_loss: 0.0231 - val_mean_squared_error: 0.0231 - val_mean_absolute_error: 0.1189\n",
            "Epoch 22/30\n",
            "7/7 [==============================] - 2s 339ms/step - loss: 0.0220 - mean_squared_error: 0.0220 - mean_absolute_error: 0.1092 - val_loss: 0.0232 - val_mean_squared_error: 0.0232 - val_mean_absolute_error: 0.1171\n",
            "Epoch 23/30\n",
            "7/7 [==============================] - 2s 275ms/step - loss: 0.0223 - mean_squared_error: 0.0222 - mean_absolute_error: 0.1090 - val_loss: 0.0218 - val_mean_squared_error: 0.0218 - val_mean_absolute_error: 0.1119\n",
            "Epoch 24/30\n",
            "7/7 [==============================] - 2s 273ms/step - loss: 0.0229 - mean_squared_error: 0.0228 - mean_absolute_error: 0.1097 - val_loss: 0.0230 - val_mean_squared_error: 0.0230 - val_mean_absolute_error: 0.1183\n",
            "Epoch 25/30\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.0230 - mean_squared_error: 0.0228 - mean_absolute_error: 0.1092 - val_loss: 0.0229 - val_mean_squared_error: 0.0229 - val_mean_absolute_error: 0.1190\n",
            "Epoch 26/30\n",
            "7/7 [==============================] - 2s 279ms/step - loss: 0.0198 - mean_squared_error: 0.0196 - mean_absolute_error: 0.1001 - val_loss: 0.0221 - val_mean_squared_error: 0.0222 - val_mean_absolute_error: 0.1155\n",
            "Epoch 27/30\n",
            "7/7 [==============================] - 2s 280ms/step - loss: 0.0207 - mean_squared_error: 0.0207 - mean_absolute_error: 0.1035 - val_loss: 0.0209 - val_mean_squared_error: 0.0209 - val_mean_absolute_error: 0.1103\n",
            "Epoch 28/30\n",
            "7/7 [==============================] - 2s 336ms/step - loss: 0.0197 - mean_squared_error: 0.0195 - mean_absolute_error: 0.1023 - val_loss: 0.0211 - val_mean_squared_error: 0.0211 - val_mean_absolute_error: 0.1101\n",
            "Epoch 29/30\n",
            "7/7 [==============================] - 2s 282ms/step - loss: 0.0188 - mean_squared_error: 0.0187 - mean_absolute_error: 0.0983 - val_loss: 0.0199 - val_mean_squared_error: 0.0200 - val_mean_absolute_error: 0.1072\n",
            "Epoch 30/30\n",
            "7/7 [==============================] - 2s 277ms/step - loss: 0.0174 - mean_squared_error: 0.0173 - mean_absolute_error: 0.0943 - val_loss: 0.0202 - val_mean_squared_error: 0.0202 - val_mean_absolute_error: 0.1093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [13:18<02:46, 166.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, None, 6)]            0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 5)]                  0         []                            \n",
            "                                                                                                  \n",
            " masking (Masking)           (None, None, 6)              0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " repeat_vector (RepeatVecto  (None, 3680, 5)              0         ['input_2[0][0]']             \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 3680, 11)             0         ['masking[0][0]',             \n",
            "                                                                     'repeat_vector[0][0]']       \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 (None, 3680, 32)             5632      ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 3680, 32)             128       ['lstm[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               (None, 3680, 32)             8320      ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 3680, 32)             128       ['lstm_1[0][0]']              \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               (None, 3680, 32)             8320      ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 3680, 32)             128       ['lstm_2[0][0]']              \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 3680, 128)            4224      ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 3680, 128)            512       ['dense[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 3680, 32)             4128      ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 3680, 32)             128       ['dense_1[0][0]']             \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 3680, 1)              33        ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                (None, 3680, 1)              0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31681 (123.75 KB)\n",
            "Trainable params: 31169 (121.75 KB)\n",
            "Non-trainable params: 512 (2.00 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 20s 2s/step - loss: 0.2273 - mean_squared_error: 0.2276 - mean_absolute_error: 0.4435 - val_loss: 0.3002 - val_mean_squared_error: 0.3002 - val_mean_absolute_error: 0.5311\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 1s 275ms/step - loss: 0.2074 - mean_squared_error: 0.2077 - mean_absolute_error: 0.4220 - val_loss: 0.2591 - val_mean_squared_error: 0.2591 - val_mean_absolute_error: 0.4915\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 1s 278ms/step - loss: 0.1898 - mean_squared_error: 0.1893 - mean_absolute_error: 0.3982 - val_loss: 0.2214 - val_mean_squared_error: 0.2214 - val_mean_absolute_error: 0.4526\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 1s 300ms/step - loss: 0.1724 - mean_squared_error: 0.1726 - mean_absolute_error: 0.3733 - val_loss: 0.1860 - val_mean_squared_error: 0.1860 - val_mean_absolute_error: 0.4135\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 1s 347ms/step - loss: 0.1572 - mean_squared_error: 0.1572 - mean_absolute_error: 0.3486 - val_loss: 0.1738 - val_mean_squared_error: 0.1738 - val_mean_absolute_error: 0.3994\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 2s 399ms/step - loss: 0.1339 - mean_squared_error: 0.1343 - mean_absolute_error: 0.3161 - val_loss: 0.1647 - val_mean_squared_error: 0.1647 - val_mean_absolute_error: 0.3881\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 1s 357ms/step - loss: 0.1141 - mean_squared_error: 0.1138 - mean_absolute_error: 0.2809 - val_loss: 0.1503 - val_mean_squared_error: 0.1503 - val_mean_absolute_error: 0.3696\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 1s 317ms/step - loss: 0.1043 - mean_squared_error: 0.1044 - mean_absolute_error: 0.2618 - val_loss: 0.1400 - val_mean_squared_error: 0.1400 - val_mean_absolute_error: 0.3553\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 1s 292ms/step - loss: 0.0909 - mean_squared_error: 0.0917 - mean_absolute_error: 0.2401 - val_loss: 0.1247 - val_mean_squared_error: 0.1247 - val_mean_absolute_error: 0.3342\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 1s 292ms/step - loss: 0.0850 - mean_squared_error: 0.0849 - mean_absolute_error: 0.2320 - val_loss: 0.1128 - val_mean_squared_error: 0.1128 - val_mean_absolute_error: 0.3159\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 1s 314ms/step - loss: 0.0726 - mean_squared_error: 0.0726 - mean_absolute_error: 0.2087 - val_loss: 0.1070 - val_mean_squared_error: 0.1070 - val_mean_absolute_error: 0.3072\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 1s 287ms/step - loss: 0.0720 - mean_squared_error: 0.0717 - mean_absolute_error: 0.2115 - val_loss: 0.0900 - val_mean_squared_error: 0.0900 - val_mean_absolute_error: 0.2774\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 1s 297ms/step - loss: 0.0713 - mean_squared_error: 0.0717 - mean_absolute_error: 0.2097 - val_loss: 0.0786 - val_mean_squared_error: 0.0786 - val_mean_absolute_error: 0.2572\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 1s 299ms/step - loss: 0.0561 - mean_squared_error: 0.0562 - mean_absolute_error: 0.1807 - val_loss: 0.0758 - val_mean_squared_error: 0.0758 - val_mean_absolute_error: 0.2530\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 1s 272ms/step - loss: 0.0521 - mean_squared_error: 0.0522 - mean_absolute_error: 0.1701 - val_loss: 0.0722 - val_mean_squared_error: 0.0722 - val_mean_absolute_error: 0.2437\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 1s 394ms/step - loss: 0.0554 - mean_squared_error: 0.0554 - mean_absolute_error: 0.1778 - val_loss: 0.0736 - val_mean_squared_error: 0.0736 - val_mean_absolute_error: 0.2471\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 2s 414ms/step - loss: 0.0461 - mean_squared_error: 0.0460 - mean_absolute_error: 0.1602 - val_loss: 0.0694 - val_mean_squared_error: 0.0694 - val_mean_absolute_error: 0.2392\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 1s 290ms/step - loss: 0.0443 - mean_squared_error: 0.0443 - mean_absolute_error: 0.1569 - val_loss: 0.0616 - val_mean_squared_error: 0.0616 - val_mean_absolute_error: 0.2214\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 1s 299ms/step - loss: 0.0492 - mean_squared_error: 0.0501 - mean_absolute_error: 0.1660 - val_loss: 0.0613 - val_mean_squared_error: 0.0613 - val_mean_absolute_error: 0.2200\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 1s 306ms/step - loss: 0.0360 - mean_squared_error: 0.0357 - mean_absolute_error: 0.1346 - val_loss: 0.0599 - val_mean_squared_error: 0.0599 - val_mean_absolute_error: 0.2187\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 1s 300ms/step - loss: 0.0372 - mean_squared_error: 0.0369 - mean_absolute_error: 0.1420 - val_loss: 0.0574 - val_mean_squared_error: 0.0574 - val_mean_absolute_error: 0.2107\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 1s 298ms/step - loss: 0.0328 - mean_squared_error: 0.0328 - mean_absolute_error: 0.1339 - val_loss: 0.0541 - val_mean_squared_error: 0.0541 - val_mean_absolute_error: 0.2034\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 1s 273ms/step - loss: 0.0301 - mean_squared_error: 0.0300 - mean_absolute_error: 0.1263 - val_loss: 0.0528 - val_mean_squared_error: 0.0528 - val_mean_absolute_error: 0.2004\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 1s 286ms/step - loss: 0.0303 - mean_squared_error: 0.0303 - mean_absolute_error: 0.1279 - val_loss: 0.0485 - val_mean_squared_error: 0.0485 - val_mean_absolute_error: 0.1900\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 1s 285ms/step - loss: 0.0303 - mean_squared_error: 0.0301 - mean_absolute_error: 0.1230 - val_loss: 0.0490 - val_mean_squared_error: 0.0490 - val_mean_absolute_error: 0.1898\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 1s 352ms/step - loss: 0.0248 - mean_squared_error: 0.0247 - mean_absolute_error: 0.1098 - val_loss: 0.0492 - val_mean_squared_error: 0.0492 - val_mean_absolute_error: 0.1892\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 2s 405ms/step - loss: 0.0254 - mean_squared_error: 0.0254 - mean_absolute_error: 0.1150 - val_loss: 0.0459 - val_mean_squared_error: 0.0459 - val_mean_absolute_error: 0.1823\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 1s 304ms/step - loss: 0.0291 - mean_squared_error: 0.0289 - mean_absolute_error: 0.1241 - val_loss: 0.0485 - val_mean_squared_error: 0.0485 - val_mean_absolute_error: 0.1874\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 1s 287ms/step - loss: 0.0238 - mean_squared_error: 0.0239 - mean_absolute_error: 0.1128 - val_loss: 0.0520 - val_mean_squared_error: 0.0520 - val_mean_absolute_error: 0.1937\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 1s 297ms/step - loss: 0.0235 - mean_squared_error: 0.0235 - mean_absolute_error: 0.1112 - val_loss: 0.0447 - val_mean_squared_error: 0.0447 - val_mean_absolute_error: 0.1789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [14:55<00:00, 179.17s/it]\n"
          ]
        }
      ],
      "source": [
        "import talos\n",
        "\n",
        "p = {\n",
        "    'batch_size': [2, 4, 8, 16, 32],\n",
        "}\n",
        "\n",
        "scan_object = talos.Scan(x=[vital_train, info.train_dataset],\n",
        "                         y=y_train,\n",
        "                         x_val=[vital_validation, info.validation_dataset],\n",
        "                         y_val=bis.validation_dataset,\n",
        "                         experiment_name='SimpleModel_BatchSize',\n",
        "                         multi_input=True,\n",
        "                         params=p,\n",
        "                         model=simple_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scan_object.data.head()"
      ],
      "metadata": {
        "id": "jXBP7TcQzMkl",
        "outputId": "5ff3b3e8-a8bc-4376-e1bb-2feeab0493d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             start              end    duration  round_epochs      loss  \\\n",
              "0  07/06/24-202845  07/06/24-203440  354.268772            30  0.011606   \n",
              "1  07/06/24-203440  07/06/24-203749  188.933976            30  0.011809   \n",
              "2  07/06/24-203749  07/06/24-204026  156.940903            30  0.012386   \n",
              "3  07/06/24-204027  07/06/24-204203   96.210842            30  0.017378   \n",
              "4  07/06/24-204204  07/06/24-204340   96.184850            30  0.023531   \n",
              "\n",
              "   mean_squared_error  mean_absolute_error  val_loss  val_mean_squared_error  \\\n",
              "0            0.011329             0.080119  0.025490                0.022314   \n",
              "1            0.011706             0.078814  0.018977                0.018611   \n",
              "2            0.012386             0.081582  0.016953                0.016812   \n",
              "3            0.017312             0.094332  0.020209                0.020219   \n",
              "4            0.023487             0.111161  0.044744                0.044744   \n",
              "\n",
              "   val_mean_absolute_error  batch_size  \n",
              "0                 0.109923           2  \n",
              "1                 0.102551           4  \n",
              "2                 0.092570           8  \n",
              "3                 0.109291          16  \n",
              "4                 0.178871          32  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d4bfa2b-2405-45f1-abeb-15102d1b2d12\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>duration</th>\n",
              "      <th>round_epochs</th>\n",
              "      <th>loss</th>\n",
              "      <th>mean_squared_error</th>\n",
              "      <th>mean_absolute_error</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_mean_squared_error</th>\n",
              "      <th>val_mean_absolute_error</th>\n",
              "      <th>batch_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>07/06/24-202845</td>\n",
              "      <td>07/06/24-203440</td>\n",
              "      <td>354.268772</td>\n",
              "      <td>30</td>\n",
              "      <td>0.011606</td>\n",
              "      <td>0.011329</td>\n",
              "      <td>0.080119</td>\n",
              "      <td>0.025490</td>\n",
              "      <td>0.022314</td>\n",
              "      <td>0.109923</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>07/06/24-203440</td>\n",
              "      <td>07/06/24-203749</td>\n",
              "      <td>188.933976</td>\n",
              "      <td>30</td>\n",
              "      <td>0.011809</td>\n",
              "      <td>0.011706</td>\n",
              "      <td>0.078814</td>\n",
              "      <td>0.018977</td>\n",
              "      <td>0.018611</td>\n",
              "      <td>0.102551</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>07/06/24-203749</td>\n",
              "      <td>07/06/24-204026</td>\n",
              "      <td>156.940903</td>\n",
              "      <td>30</td>\n",
              "      <td>0.012386</td>\n",
              "      <td>0.012386</td>\n",
              "      <td>0.081582</td>\n",
              "      <td>0.016953</td>\n",
              "      <td>0.016812</td>\n",
              "      <td>0.092570</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>07/06/24-204027</td>\n",
              "      <td>07/06/24-204203</td>\n",
              "      <td>96.210842</td>\n",
              "      <td>30</td>\n",
              "      <td>0.017378</td>\n",
              "      <td>0.017312</td>\n",
              "      <td>0.094332</td>\n",
              "      <td>0.020209</td>\n",
              "      <td>0.020219</td>\n",
              "      <td>0.109291</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>07/06/24-204204</td>\n",
              "      <td>07/06/24-204340</td>\n",
              "      <td>96.184850</td>\n",
              "      <td>30</td>\n",
              "      <td>0.023531</td>\n",
              "      <td>0.023487</td>\n",
              "      <td>0.111161</td>\n",
              "      <td>0.044744</td>\n",
              "      <td>0.044744</td>\n",
              "      <td>0.178871</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d4bfa2b-2405-45f1-abeb-15102d1b2d12')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1d4bfa2b-2405-45f1-abeb-15102d1b2d12 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1d4bfa2b-2405-45f1-abeb-15102d1b2d12');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5e6d7bf9-c07f-4134-8722-f6000a59fc3d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5e6d7bf9-c07f-4134-8722-f6000a59fc3d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5e6d7bf9-c07f-4134-8722-f6000a59fc3d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"scan_object\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"start\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"07/06/24-203440\",\n          \"07/06/24-204204\",\n          \"07/06/24-203749\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"07/06/24-203749\",\n          \"07/06/24-204340\",\n          \"07/06/24-204026\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 106.08441579931069,\n        \"min\": 96.1848497390747,\n        \"max\": 354.2687723636627,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          188.9339759349823,\n          96.1848497390747,\n          156.94090270996094\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"round_epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 30,\n        \"max\": 30,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          30\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005157137683268823,\n        \"min\": 0.01160553377121687,\n        \"max\": 0.02353072725236416,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.011808653362095356\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_squared_error\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005201747377119795,\n        \"min\": 0.01132948137819767,\n        \"max\": 0.023487215861678123,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.01170622929930687\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_absolute_error\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013756826694631135,\n        \"min\": 0.07881350070238113,\n        \"max\": 0.11116079986095428,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.07881350070238113\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011332224756144114,\n        \"min\": 0.01695307157933712,\n        \"max\": 0.044744182378053665,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.018977221101522446\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_mean_squared_error\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011475164180743591,\n        \"min\": 0.016811583191156387,\n        \"max\": 0.044744182378053665,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0186106339097023\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_mean_absolute_error\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.034386445979670305,\n        \"min\": 0.09257001429796219,\n        \"max\": 0.1788712739944458,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.10255055874586105\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 2,\n        \"max\": 32,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scan_object.details"
      ],
      "metadata": {
        "id": "kShQDTN1yoJd",
        "outputId": "35218861-95b8-49e0-ca9f-b41406493a38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "experiment_name        SimpleModel_BatchSize\n",
              "random_method               uniform_mersenne\n",
              "reduction_method                        None\n",
              "reduction_interval                        50\n",
              "reduction_window                          20\n",
              "reduction_threshold                      0.2\n",
              "reduction_metric                     val_acc\n",
              "experiment_id                   070624202845\n",
              "complete_time                 07/06/24/20:43\n",
              "x_shape                          multi-input\n",
              "y_shape                       (111, 3680, 1)\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}